{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Testing\n",
    "After training and saving the model to local, now it is time to test it! First apply the same data reformatting and processing method on the task dataset, then feed the processed data to model to calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = {'Pulling_OneH': 0, 'Overhead': 1, 'Pulling': 2, 'Sitting': 3, \n",
    "              'Lifting': 4, 'Crawling': 5, 'Standing': 6, 'Carrying': 7, \n",
    "              'Walking': 8, 'Pushing': 9, 'Reaching': 10, 'Static_Stoop': 11, \n",
    "              'Kneeling': 12, 'Lifting_OneH': 13, 'Crouching': 14}\n",
    "\n",
    "header = ['TimeSec', 'Sensor', 'Quatx', 'Quaty', 'Quatz', 'Quat0', 'Heading',\n",
    "       'Pitch', 'Roll', 'LinAccx', 'LinAccy', 'LinAccz', 'Vbat', 'Accx',\n",
    "       'Accy', 'Accz', 'Gyrox', 'Gyroy', 'Gyroz']\n",
    "\n",
    "# actually {1.0, 3.0, 5.0, 6.0, 8.0, 10.0, 12.0, 14.0} in the task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Spinetrack Data/task/\"\n",
    "name_dir = []\n",
    "\n",
    "for d in sorted(os.listdir(directory)):\n",
    "    name_dir.append(d)\n",
    "#name_dir\n",
    "\n",
    "total_data = []\n",
    "for d in name_dir:\n",
    "    try:\n",
    "        # parsing timestep txt file\n",
    "        index_text = open('./Spinetrack Data/task/{0}/timeStamps_Everything.txt'.format(d), 'r').readlines()\n",
    "        act_index = []\n",
    "        for line in index_text[1:]:\n",
    "            row = line.rstrip().split('\\t')\n",
    "            if len(row[2].split('_')) > 1 and row[2].split('_')[1] == 'OneH':\n",
    "                row[2] = '_'.join(row[2].split('_')[:2])\n",
    "            else:\n",
    "                row[2] = row[2].split('_')[0]\n",
    "\n",
    "            if row[2] not in index_dict.keys():\n",
    "                row.append(999)\n",
    "            else:\n",
    "                row.append(index_dict[row[2]])\n",
    "\n",
    "            act_index.append(row)\n",
    "        index_df = pd.DataFrame(act_index)\n",
    "        index_df.columns = ['Frame', 'Time(s)', 'Task', 'Index']\n",
    "\n",
    "        # parsing everything csv file\n",
    "        recording_df = pd.read_csv('./Spinetrack Data/task/{0}/Everything.csv'.format(d), error_bad_lines=False).dropna()\n",
    "        recording_df.columns = header\n",
    "#         print(recording_df)\n",
    "\n",
    "        # adding activity columns\n",
    "        frame = []\n",
    "        for index in range(1, len(index_df)):\n",
    "            activity_index = index_df.iloc[index - 1]['Index']\n",
    "            if activity_index != 999:\n",
    "                time_lower_bound = float(index_df.iloc[index - 1]['Time(s)'])\n",
    "                time_upper_bound = float(index_df.iloc[index]['Time(s)'])\n",
    "                df_part = recording_df.loc[(recording_df['TimeSec'] >= (time_lower_bound + 2)) & (recording_df['TimeSec'] < (time_upper_bound - 2))]\n",
    "                df_part['activity'] = [int(activity_index) for i in range(len(df_part))]\n",
    "                frame.append(df_part)\n",
    "        data_df = pd.concat(frame)\n",
    "        total_data.append(data_df)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "result_df = pd.concat(total_data)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter\n",
    "window_size: The number of timesteps in one window (e.g. how many rows in one window).\n",
    "\n",
    "channel: The number of features in one window. Similar to image channels (RGB).\n",
    "\n",
    "batch_size: The numebr of windows in one batch.\n",
    "\n",
    "learning_rate: How fast the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 540\n",
    "channel = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Go to \n",
    "<a href=#bookmark> Run all cell above</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.930684\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 20% (1450/7057) for (10) window_size\n",
      "\n",
      "Test Loss: 3.460707\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 39% (1372/3492) for (20) window_size\n",
      "\n",
      "Test Loss: 2.995006\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 48% (1114/2304) for (30) window_size\n",
      "\n",
      "Test Loss: 3.236589\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 41% (714/1711) for (40) window_size\n",
      "\n",
      "Test Loss: 2.708776\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 51% (699/1353) for (50) window_size\n",
      "\n",
      "Test Loss: 2.487063\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 54% (612/1117) for (60) window_size\n",
      "\n",
      "Test Loss: 2.681676\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 52% (492/946) for (70) window_size\n",
      "\n",
      "Test Loss: 2.621060\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 52% (434/821) for (80) window_size\n",
      "\n",
      "Test Loss: 2.445205\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 58% (421/720) for (90) window_size\n",
      "\n",
      "Test Loss: 2.482856\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 51% (327/640) for (100) window_size\n",
      "\n",
      "Test Loss: 2.472588\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 57% (330/578) for (110) window_size\n",
      "\n",
      "Test Loss: 2.286891\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 56% (295/523) for (120) window_size\n",
      "\n",
      "Test Loss: 2.384305\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 56% (271/478) for (130) window_size\n",
      "\n",
      "Test Loss: 2.405028\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 56% (246/437) for (140) window_size\n",
      "\n",
      "Test Loss: 2.154422\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (247/404) for (150) window_size\n",
      "\n",
      "Test Loss: 2.248284\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 58% (219/376) for (160) window_size\n",
      "\n",
      "Test Loss: 2.323392\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 58% (203/349) for (170) window_size\n",
      "\n",
      "Test Loss: 2.244718\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 59% (193/325) for (180) window_size\n",
      "\n",
      "Test Loss: 2.175279\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (187/305) for (190) window_size\n",
      "\n",
      "Test Loss: 2.266125\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 54% (156/287) for (200) window_size\n",
      "\n",
      "Test Loss: 2.160350\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (169/269) for (210) window_size\n",
      "\n",
      "Test Loss: 2.160614\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (154/254) for (220) window_size\n",
      "\n",
      "Test Loss: 2.237668\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 57% (138/240) for (230) window_size\n",
      "\n",
      "Test Loss: 2.122350\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (138/227) for (240) window_size\n",
      "\n",
      "Test Loss: 2.181098\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (131/215) for (250) window_size\n",
      "\n",
      "Test Loss: 2.199958\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (126/205) for (260) window_size\n",
      "\n",
      "Test Loss: 2.286240\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (122/194) for (270) window_size\n",
      "\n",
      "Test Loss: 2.186322\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (114/185) for (280) window_size\n",
      "\n",
      "Test Loss: 2.340529\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (106/176) for (290) window_size\n",
      "\n",
      "Test Loss: 2.006182\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (103/168) for (300) window_size\n",
      "\n",
      "Test Loss: 2.139424\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (102/162) for (310) window_size\n",
      "\n",
      "Test Loss: 2.073883\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (94/155) for (320) window_size\n",
      "\n",
      "Test Loss: 2.108902\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (93/148) for (330) window_size\n",
      "\n",
      "Test Loss: 2.149311\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (84/140) for (340) window_size\n",
      "\n",
      "Test Loss: 2.028505\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 65% (88/134) for (350) window_size\n",
      "\n",
      "Test Loss: 2.169570\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (81/130) for (360) window_size\n",
      "\n",
      "Test Loss: 2.063490\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (81/125) for (370) window_size\n",
      "\n",
      "Test Loss: 2.155077\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (75/121) for (380) window_size\n",
      "\n",
      "Test Loss: 2.201043\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (72/116) for (390) window_size\n",
      "\n",
      "Test Loss: 2.048995\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (69/111) for (400) window_size\n",
      "\n",
      "Test Loss: 2.030172\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 66% (73/110) for (410) window_size\n",
      "\n",
      "Test Loss: 2.109380\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (63/103) for (420) window_size\n",
      "\n",
      "Test Loss: 2.084113\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (61/100) for (430) window_size\n",
      "\n",
      "Test Loss: 2.001195\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (59/95) for (440) window_size\n",
      "\n",
      "Test Loss: 2.189273\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (57/93) for (450) window_size\n",
      "\n",
      "Test Loss: 1.952071\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (55/90) for (460) window_size\n",
      "\n",
      "Test Loss: 2.192609\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (53/85) for (470) window_size\n",
      "\n",
      "Test Loss: 1.934700\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 63% (53/84) for (480) window_size\n",
      "\n",
      "Test Loss: 2.250765\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (51/79) for (490) window_size\n",
      "\n",
      "Test Loss: 2.157002\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 58% (46/79) for (500) window_size\n",
      "\n",
      "Test Loss: 1.732760\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 66% (50/75) for (510) window_size\n",
      "\n",
      "Test Loss: 2.039901\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (47/73) for (520) window_size\n",
      "\n",
      "Test Loss: 2.070488\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (44/70) for (530) window_size\n",
      "\n",
      "Test Loss: 1.892684\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (42/67) for (540) window_size\n",
      "\n",
      "Test Loss: 2.064895\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 68% (44/64) for (550) window_size\n",
      "\n",
      "Test Loss: 1.819172\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (41/64) for (560) window_size\n",
      "\n",
      "Test Loss: 2.077477\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (38/59) for (570) window_size\n",
      "\n",
      "Test Loss: 1.858877\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (37/59) for (580) window_size\n",
      "\n",
      "Test Loss: 1.857503\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (38/59) for (590) window_size\n",
      "\n",
      "Test Loss: 2.088079\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (33/54) for (600) window_size\n",
      "\n",
      "Test Loss: 1.701829\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 64% (34/53) for (610) window_size\n",
      "\n",
      "Test Loss: 1.892876\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 59% (31/52) for (620) window_size\n",
      "\n",
      "Test Loss: 1.810244\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 67% (35/52) for (630) window_size\n",
      "\n",
      "Test Loss: 1.596232\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 60% (30/50) for (640) window_size\n",
      "\n",
      "Test Loss: 1.976518\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 63% (29/46) for (650) window_size\n",
      "\n",
      "Test Loss: 1.571750\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 69% (32/46) for (660) window_size\n",
      "\n",
      "Test Loss: 2.190137\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 62% (27/43) for (670) window_size\n",
      "\n",
      "Test Loss: 1.805384\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 61% (26/42) for (680) window_size\n",
      "\n",
      "Test Loss: 1.664850\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 72% (31/43) for (690) window_size\n",
      "\n",
      "Test Loss: 1.812974\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 70% (29/41) for (700) window_size\n",
      "\n",
      "Test Loss: 1.795869\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 63% (24/38) for (710) window_size\n",
      "\n",
      "Test Loss: 1.794220\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 65% (26/40) for (720) window_size\n",
      "\n",
      "Test Loss: 1.734127\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 71% (27/38) for (730) window_size\n",
      "\n",
      "Test Loss: 1.581128\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 72% (26/36) for (740) window_size\n",
      "\n",
      "[(740, 72.22222222222223), (690, 72.09302325581395), (730, 71.05263157894737), (700, 70.73170731707317), (660, 69.56521739130434), (550, 68.75), (630, 67.3076923076923), (510, 66.66666666666667), (410, 66.36363636363636), (350, 65.67164179104478), (720, 65.0), (370, 64.8), (490, 64.55696202531645), (570, 64.40677966101696), (590, 64.40677966101696), (520, 64.38356164383562), (610, 64.15094339622641), (560, 64.0625), (710, 63.1578947368421), (480, 63.095238095238095), (650, 63.04347826086956), (310, 62.96296296296296), (270, 62.88659793814433), (530, 62.857142857142854), (330, 62.83783783783784), (210, 62.825278810408925), (670, 62.7906976744186), (580, 62.71186440677966), (540, 62.6865671641791), (470, 62.35294117647059), (360, 62.30769230769231), (400, 62.16216216216216), (440, 62.10526315789474), (390, 62.06896551724138), (380, 61.98347107438016), (680, 61.904761904761905), (280, 61.62162162162162), (260, 61.46341463414634), (190, 61.31147540983606), (300, 61.30952380952381), (450, 61.29032258064516), (420, 61.16504854368932), (150, 61.13861386138614), (460, 61.111111111111114), (600, 61.111111111111114), (430, 61.0), (250, 60.93023255813954), (240, 60.79295154185022), (320, 60.645161290322584), (220, 60.62992125984252), (290, 60.22727272727273), (340, 60.0), (640, 60.0), (620, 59.61538461538461), (180, 59.38461538461539), (90, 58.47222222222222), (160, 58.244680851063826), (500, 58.22784810126582), (170, 58.16618911174785), (230, 57.5), (110, 57.09342560553633), (130, 56.69456066945607), (120, 56.40535372848949), (140, 56.2929061784897), (60, 54.789615040286485), (200, 54.35540069686411), (80, 52.862362971985384), (70, 52.00845665961945), (50, 51.6629711751663), (100, 51.09375), (30, 48.35069444444444), (40, 41.72998246639392), (20, 39.289805269186715), (10, 20.546974635114072)]\n"
     ]
    }
   ],
   "source": [
    "ranking = {}\n",
    "for window_size in range(10, 750, 10):\n",
    "#     window_size = i\n",
    "    \n",
    "    \n",
    "    # Process original dataset, create windows (window_size samples(rows), about 1 second)\n",
    "    data = []\n",
    "    window = 1\n",
    "    while window*window_size < len(result_df):\n",
    "        data_window = result_df[(window - 1)*window_size:window*window_size]\n",
    "        data.append(data_window.values)\n",
    "        window += 1\n",
    "    #data\n",
    "\n",
    "    # delete window if multiple activities and sensors presents\n",
    "    cleaned_data = []\n",
    "    for i in data:\n",
    "        previous_activity = -1\n",
    "        previous_sensor = -1\n",
    "        for j in i:\n",
    "            current_activity = j[19]\n",
    "            current_sensor = j[1]\n",
    "            if (previous_activity != -1) and (current_activity != previous_activity):\n",
    "#                 print(\"data contains different activities! Window droped\")\n",
    "                break\n",
    "    #         elif (previous_sensor != -1) and (current_sensor != previous_sensor):\n",
    "    #             print(\"data contains different sensors! Window droped\")\n",
    "    #             break\n",
    "            else:\n",
    "                previous_activity = current_activity\n",
    "                previous_sensor = current_sensor\n",
    "        else:\n",
    "            cleaned_data.append(i)\n",
    "\n",
    "    # extract label from each window\n",
    "    labels = []\n",
    "    for i in cleaned_data:\n",
    "        label = i[0][19]\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels)\n",
    "    #labels\n",
    "\n",
    "    # extract features from each window\n",
    "    features = []\n",
    "    for i in cleaned_data:\n",
    "        new = np.delete(i, 19, 1)\n",
    "        features.append(new)\n",
    "    features = np.array(features)\n",
    "    #features\n",
    "\n",
    "    # combine the features and labels\n",
    "    k = list(zip(features, labels))\n",
    "    activity_data = pd.DataFrame(k)\n",
    "    activity_data.columns = ['features', 'labels']\n",
    "    activity_data\n",
    "\n",
    "    # check the size of activity. The final output of neural net \n",
    "    # has to have max_index + 1 output\n",
    "    max_index = activity_data['labels'].max()\n",
    "    label_size = int(max_index + 1)\n",
    "\n",
    "    # define our dataset in pytorch\n",
    "    class DatasetSpineTrack(Dataset):\n",
    "\n",
    "        def __init__(self, file, transform=None):\n",
    "            #self.data = pd.read_csv(file_path)\n",
    "            self.data = file\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            # load image as ndarray type (Height * Width * Channels)\n",
    "            # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "            # in this example, i don't use ToTensor() method of torchvision.transforms\n",
    "            # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
    "\n",
    "            features = torch.tensor(self.data[\"features\"].iloc[index])\n",
    "            features = features.view(channel, window_size, 19) \n",
    "            labels = torch.tensor(self.data[\"labels\"].iloc[index], dtype=torch.long)\n",
    "            #print(labels.type())\n",
    "\n",
    "    #         if self.transform is not None:\n",
    "    #             image = self.transform(image)\n",
    "\n",
    "            return features, labels\n",
    "\n",
    "    # create test data set\n",
    "    activity_data_test = activity_data\n",
    "    test_dataset = DatasetSpineTrack(activity_data_test)\n",
    "\n",
    "    # load data\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    train_on_gpu = False\n",
    "\n",
    "    # define the model\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    # window_size channels\n",
    "    model.conv1 = torch.nn.Conv2d(channel, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model.fc = torch.nn.Linear(512, label_size, bias=True)\n",
    "    model.add_module(\"dropout\", torch.nn.Dropout(p=0.5))\n",
    "    model = model.double()\n",
    "\n",
    "    # move tensors to GPU is CUDA is available\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "#     print(model)\n",
    "\n",
    "    # load model\n",
    "    # model.load_state_dict(torch.load('model_Spinetrack_3.pt'))\n",
    "\n",
    "    # if wanty to run in cpu...\n",
    "    model.load_state_dict(torch.load('model_Spinetrack_11.pt', map_location=lambda storage, loc: storage))\n",
    "\n",
    "    # track test loss\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(len(index_dict)))\n",
    "    class_total = list(0. for i in range(len(index_dict)))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.eval()\n",
    "    torch.no_grad()\n",
    "    # iterate over test data\n",
    "    for features, labels in testloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(features)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, labels)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*features.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                label = labels.data[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # average test loss\n",
    "    test_loss = test_loss/len(testloader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "#     for i in range(len(index_dict)):\n",
    "#         if class_total[i] > 0:\n",
    "#             print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "#                 list(index_dict.keys())[i], 100 * class_correct[i] / class_total[i],\n",
    "#                 np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#         else:\n",
    "#             print('Test Accuracy of %5s: N/A (no training examples)' % (list(index_dict.keys())[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d) for (%2d) window_size' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total), window_size))\n",
    "    print()\n",
    "    \n",
    "    accuracy = 100. * np.sum(class_correct) / np.sum(class_total)\n",
    "    ranking[window_size] = accuracy\n",
    "    \n",
    "print(sorted(ranking.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## model 3 (60):\n",
    "(740, 86.11111111111111), (660, 80.43478260869566), (720, 80.0), (520, 76.71232876712328), (710, 76.3157894736842), (580, 76.27118644067797), (540, 76.11940298507463), (650, 76.08695652173913), (640, 76.0), (700, 75.60975609756098), (560, 75.0), (630, 75.0), (680, 73.80952380952381), (460, 73.33333333333333), (620, 73.07692307692308), (480, 72.61904761904762), (600, 72.22222222222223), (490, 72.15189873417721), (690, 72.09302325581395), (510, 72.0), (550, 71.875), (570, 71.1864406779661), (450, 70.96774193548387), (500, 70.88607594936708), (400, 70.27027027027027), (380, 70.24793388429752), (350, 70.14925373134328), (590, 69.49152542372882), (340, 69.28571428571429), (280, 69.1891891891892), (370, 68.8), (530, 68.57142857142857), (440, 68.42105263157895), (730, 68.42105263157895), (410, 68.18181818181819), (360, 67.6923076923077), (670, 67.44186046511628), (260, 67.3170731707317), (300, 67.26190476190476), (470, 67.05882352941177), (420, 66.99029126213593), (320, 66.45161290322581), (240, 66.07929515418502), (310, 66.04938271604938), (430, 66.0), (220, 65.74803149606299), (390, 65.51724137931035), (270, 64.43298969072166), (290, 64.20454545454545), (330, 64.1891891891892), (610, 64.15094339622641), (180, 63.69230769230769), (250, 63.25581395348837), (200, 63.066202090592334), (190, 62.622950819672134), (160, 62.234042553191486), (210, 62.0817843866171), (120, 61.95028680688336), (230, 61.666666666666664), (170, 61.03151862464183), (150, 60.89108910891089), (140, 60.869565217391305), (100, 59.6875), (130, 59.62343096234309), (110, 59.16955017301038), (90, 58.333333333333336), (80, 57.97807551766139), (70, 57.399577167019025), (60, 57.38585496866607), (50, 55.432372505543235), (40, 49.4447691408533), (30, 42.751736111111114), (20, 38.373424971363114), (10, 14.453733881252656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## model 5 (120):\n",
    "[(730, 78.94736842105263), (620, 75.0), (670, 72.09302325581395), (520, 71.23287671232876), (700, 70.73170731707317), (640, 70.0), (720, 70.0), (650, 69.56521739130434), (660, 69.56521739130434), (740, 69.44444444444444), (630, 69.23076923076923), (600, 68.51851851851852), (490, 68.35443037974683), (510, 68.0), (480, 67.85714285714286), (580, 67.79661016949153), (560, 67.1875), (540, 67.16417910447761), (530, 67.14285714285714), (680, 66.66666666666667), (320, 66.45161290322581), (250, 66.04651162790698), (500, 65.82278481012658), (400, 65.76576576576576), (550, 65.625), (690, 65.11627906976744), (350, 64.92537313432835), (310, 64.81481481481481), (460, 64.44444444444444), (340, 64.28571428571429), (420, 64.07766990291262), (440, 63.1578947368421), (360, 63.07692307692308), (260, 62.4390243902439), (610, 62.264150943396224), (280, 62.16216216216216), (200, 62.02090592334495), (410, 61.81818181818182), (220, 61.811023622047244), (210, 61.71003717472119), (240, 61.67400881057269), (370, 61.6), (450, 61.29032258064516), (160, 61.170212765957444), (380, 61.15702479338843), (590, 61.016949152542374), (120, 60.994263862332694), (230, 60.833333333333336), (300, 60.714285714285715), (180, 60.61538461538461), (710, 60.526315789473685), (390, 60.3448275862069), (190, 60.32786885245902), (270, 59.79381443298969), (570, 59.32203389830509), (140, 59.267734553775746), (150, 59.15841584158416), (430, 59.0), (470, 58.8235294117647), (330, 58.78378378378378), (170, 58.16618911174785), (290, 57.38636363636363), (90, 57.083333333333336), (80, 57.003654080389765), (60, 54.25246195165622), (110, 53.806228373702425), (100, 52.5), (130, 52.09205020920502), (50, 50.25868440502587), (70, 46.723044397463), (30, 33.767361111111114), (40, 31.09292811221508), (20, 31.013745704467354), (10, 8.289641490718436)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## model 10 (45):\n",
    "[(590, 77.96610169491525), (740, 77.77777777777777), (710, 76.3157894736842), (570, 76.27118644067797), (680, 76.19047619047619), (660, 76.08695652173913), (510, 74.66666666666667), (540, 74.6268656716418), (690, 74.4186046511628), (490, 73.41772151898734), (700, 73.17073170731707), (470, 72.94117647058823), (720, 72.5), (460, 72.22222222222223), (600, 72.22222222222223), (450, 72.04301075268818), (430, 72.0), (560, 71.875), (610, 71.69811320754717), (440, 71.57894736842105), (390, 71.55172413793103), (520, 71.23287671232876), (580, 71.1864406779661), (400, 71.17117117117117), (620, 71.15384615384616), (630, 71.15384615384616), (730, 71.05263157894737), (380, 70.24793388429752), (410, 70.0), (530, 70.0), (640, 70.0), (420, 69.90291262135922), (300, 69.64285714285714), (500, 69.62025316455696), (370, 69.6), (330, 69.5945945945946), (650, 69.56521739130434), (290, 69.31818181818181), (480, 69.04761904761905), (360, 68.46153846153847), (140, 68.19221967963387), (230, 67.91666666666667), (240, 67.84140969162996), (260, 67.8048780487805), (320, 67.74193548387096), (250, 67.44186046511628), (310, 67.28395061728395), (350, 67.16417910447761), (340, 67.14285714285714), (280, 67.02702702702703), (130, 66.94560669456067), (190, 66.55737704918033), (210, 66.54275092936803), (220, 66.53543307086615), (170, 66.189111747851), (120, 66.1567877629063), (270, 65.97938144329896), (150, 65.84158415841584), (110, 65.7439446366782), (80, 65.6516443361754), (180, 65.53846153846153), (160, 65.42553191489361), (90, 65.27777777777777), (670, 65.11627906976744), (200, 64.80836236933798), (100, 64.6875), (50, 64.44937176644494), (60, 64.27931960608774), (550, 64.0625), (70, 63.00211416490486), (40, 61.776738749269434), (30, 53.21180555555556), (20, 51.3745704467354), (10, 29.233385291200225)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## model 11 (90):\n",
    "[(740, 72.22222222222223), (690, 72.09302325581395), (730, 71.05263157894737), (700, 70.73170731707317), (660, 69.56521739130434), (550, 68.75), (630, 67.3076923076923), (510, 66.66666666666667), (410, 66.36363636363636), (350, 65.67164179104478), (720, 65.0), (370, 64.8), (490, 64.55696202531645), (570, 64.40677966101696), (590, 64.40677966101696), (520, 64.38356164383562), (610, 64.15094339622641), (560, 64.0625), (710, 63.1578947368421), (480, 63.095238095238095), (650, 63.04347826086956), (310, 62.96296296296296), (270, 62.88659793814433), (530, 62.857142857142854), (330, 62.83783783783784), (210, 62.825278810408925), (670, 62.7906976744186), (580, 62.71186440677966), (540, 62.6865671641791), (470, 62.35294117647059), (360, 62.30769230769231), (400, 62.16216216216216), (440, 62.10526315789474), (390, 62.06896551724138), (380, 61.98347107438016), (680, 61.904761904761905), (280, 61.62162162162162), (260, 61.46341463414634), (190, 61.31147540983606), (300, 61.30952380952381), (450, 61.29032258064516), (420, 61.16504854368932), (150, 61.13861386138614), (460, 61.111111111111114), (600, 61.111111111111114), (430, 61.0), (250, 60.93023255813954), (240, 60.79295154185022), (320, 60.645161290322584), (220, 60.62992125984252), (290, 60.22727272727273), (340, 60.0), (640, 60.0), (620, 59.61538461538461), (180, 59.38461538461539), (90, 58.47222222222222), (160, 58.244680851063826), (500, 58.22784810126582), (170, 58.16618911174785), (230, 57.5), (110, 57.09342560553633), (130, 56.69456066945607), (120, 56.40535372848949), (140, 56.2929061784897), (60, 54.789615040286485), (200, 54.35540069686411), (80, 52.862362971985384), (70, 52.00845665961945), (50, 51.6629711751663), (100, 51.09375), (30, 48.35069444444444), (40, 41.72998246639392), (20, 39.289805269186715), (10, 20.546974635114072)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single test set\n",
    "\n",
    "\n",
    "# index_text = open('./Spinetrack Data/task/Alex_task/timeStamps_Everything.txt', 'r').readlines()\n",
    "# act_index = []\n",
    "# for line in index_text[1:]:\n",
    "#     row = line.rstrip().split('\\t')\n",
    "#     if len(row[2].split('_')) > 1 and row[2].split('_')[1] == 'OneH':\n",
    "#         row[2] = '_'.join(row[2].split('_')[:2])\n",
    "#     else:\n",
    "#         row[2] = row[2].split('_')[0]\n",
    "    \n",
    "#     if row[2] not in index_dict.keys():\n",
    "#         row.append(999)\n",
    "#     else:\n",
    "#         row.append(index_dict[row[2]])\n",
    "    \n",
    "#     act_index.append(row)\n",
    "# index_df = pd.DataFrame(act_index)\n",
    "# index_df.columns = ['Frame', 'Time(s)', 'Task', 'Index']\n",
    "\n",
    "# recording_df = pd.read_csv('./Spinetrack Data/task/Alex_task/Everything.csv', error_bad_lines=False).dropna()\n",
    "# recording_df.columns = header\n",
    "# print(recording_df)\n",
    "\n",
    "# frame = []\n",
    "# for index in range(1, len(index_df)):\n",
    "#     activity_index = index_df.iloc[index - 1]['Index']\n",
    "#     if activity_index != 999:\n",
    "#         time_lower_bound = float(index_df.iloc[index - 1]['Time(s)'])\n",
    "#         time_upper_bound = float(index_df.iloc[index]['Time(s)'])\n",
    "#         df_part = recording_df.loc[(recording_df['TimeSec'] >= (time_lower_bound + 2)) & (recording_df['TimeSec'] < (time_upper_bound - 2))]\n",
    "#         df_part['activity'] = activity_index\n",
    "#         frame.append(df_part)\n",
    "\n",
    "# data_df = pd.concat(frame)\n",
    "# data_df\n",
    "\n",
    "# result_df = data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release all the GPU memory cache that can be freed\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy and each class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.572834\n",
      "\n",
      "Test Accuracy of Pulling_OneH: N/A (no training examples)\n",
      "Test Accuracy of Overhead: 100% (13/13)\n",
      "Test Accuracy of Pulling: N/A (no training examples)\n",
      "Test Accuracy of Sitting: 66% ( 4/ 6)\n",
      "Test Accuracy of Lifting: N/A (no training examples)\n",
      "Test Accuracy of Crawling: 100% ( 5/ 5)\n",
      "Test Accuracy of Standing: 46% ( 6/13)\n",
      "Test Accuracy of Carrying: N/A (no training examples)\n",
      "Test Accuracy of Walking: 71% ( 5/ 7)\n",
      "Test Accuracy of Pushing: N/A (no training examples)\n",
      "Test Accuracy of Reaching: 76% (20/26)\n",
      "Test Accuracy of Static_Stoop: N/A (no training examples)\n",
      "Test Accuracy of Kneeling: 100% ( 1/ 1)\n",
      "Test Accuracy of Lifting_OneH: N/A (no training examples)\n",
      "Test Accuracy of Crouching: 37% ( 3/ 8)\n",
      "\n",
      "Test Accuracy (Overall): 72% (57/79)\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(len(index_dict)))\n",
    "class_total = list(0. for i in range(len(index_dict)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.NLLLoss()\n",
    "initial\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.eval()\n",
    "torch.no_grad()\n",
    "# iterate over test data\n",
    "for features, labels in testloader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(features)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, labels)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*features.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        try:\n",
    "            label = labels.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(testloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(len(index_dict)):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            list(index_dict.keys())[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (list(index_dict.keys())[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Run all above \n",
    "<a name='bookmark' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
