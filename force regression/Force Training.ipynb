{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and reformating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\\\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from random import shuffle, seed\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter\n",
    "window_size: The number of timesteps in one window (e.g. how many rows in one window).\n",
    "\n",
    "channel: The number of features in one window. Similar to image channels (RGB).\n",
    "\n",
    "batch_size: The numebr of windows in one batch.\n",
    "\n",
    "learning_rate: How fast the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "channel = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Go to \n",
    "<a href=#bookmark> Run all cell above</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_lst = []\n",
    "# index_dict = {}\n",
    "# for i in sorted(os.listdir('./Spinetrack Data/data/Alex_data/Processed_redone')):\n",
    "#     if i.endswith(\".csv\") and i.startswith(\"L_\"): \n",
    "#         # should we combinme same activities together?\n",
    "#         act_lst = i.split('.')[0]\n",
    "#         act = act_lst\n",
    "#         #act = i.split('.')[0]\n",
    "#         index_lst.append(act)\n",
    "\n",
    "# index_set = set(index_lst)\n",
    "        \n",
    "# # delete multiple items\n",
    "# index_dict = {act:i for i, act in enumerate(index_set)}\n",
    "# index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 number of activity: 79\n",
      "s12 number of activity: 87\n",
      "s13 number of activity: 88\n",
      "s2 number of activity: 90\n",
      "s3 number of activity: 77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['./all/s1/MVC100-1sub01.csv',\n",
       "  './all/s1/MVC100-2sub01.csv',\n",
       "  './all/s1/MVC100-3sub01.csv',\n",
       "  './all/s1/MVC25-1sub01.csv',\n",
       "  './all/s1/MVC25-2sub01.csv',\n",
       "  './all/s1/MVC50-1sub01.csv',\n",
       "  './all/s1/MVC50-2sub01.csv',\n",
       "  './all/s1/MVC75-1sub01.csv',\n",
       "  './all/s1/MVC75-2sub01.csv',\n",
       "  './all/s1/MVCEXT100-1sub01.csv',\n",
       "  './all/s1/MVCEXT100-2sub01.csv',\n",
       "  './all/s1/MVCEXT100-3sub01.csv',\n",
       "  './all/s1/MVCEXT25-1sub01.csv',\n",
       "  './all/s1/MVCEXT25-2sub01.csv',\n",
       "  './all/s1/MVCEXT50-1sub01.csv',\n",
       "  './all/s1/MVCEXT50-2sub01.csv',\n",
       "  './all/s1/MVCEXT75-1sub01.csv',\n",
       "  './all/s1/MVCEXT75-2sub01.csv',\n",
       "  './all/s1/MVCFLX100-1sub01.csv',\n",
       "  './all/s1/MVCFLX100-2sub01.csv',\n",
       "  './all/s1/MVCFLX100-3sub01.csv',\n",
       "  './all/s1/MVCFLX25-1sub01.csv',\n",
       "  './all/s1/MVCFLX25-2sub01.csv',\n",
       "  './all/s1/MVCFLX50-1sub01.csv',\n",
       "  './all/s1/MVCFLX50-2sub01.csv',\n",
       "  './all/s1/MVCFLX75-1sub01.csv',\n",
       "  './all/s1/MVCFLX75-2sub01.csv',\n",
       "  './all/s1/MVCRD100-1sub01.csv',\n",
       "  './all/s1/MVCRD100-2sub01.csv',\n",
       "  './all/s1/MVCRD100-3sub01.csv',\n",
       "  './all/s1/MVCRD25-1sub01.csv',\n",
       "  './all/s1/MVCRD25-2sub01.csv',\n",
       "  './all/s1/MVCRD50-1sub01.csv',\n",
       "  './all/s1/MVCRD50-2sub01.csv',\n",
       "  './all/s1/MVCRD75-1sub01.csv',\n",
       "  './all/s1/MVCRD75-2sub01.csv',\n",
       "  './all/s1/MVCUD100-1sub01.csv',\n",
       "  './all/s1/MVCUD100-2sub01.csv',\n",
       "  './all/s1/MVCUD100-3sub01.csv',\n",
       "  './all/s1/MVCUD25-1sub01.csv',\n",
       "  './all/s1/MVCUD25-2sub01.csv',\n",
       "  './all/s1/MVCUD50-1sub01.csv',\n",
       "  './all/s1/MVCUD50-2sub01.csv',\n",
       "  './all/s1/MVCUD75-1sub01.csv',\n",
       "  './all/s1/MVCUD75-2sub01.csv',\n",
       "  './all/s1/PMVC100-1sub01.csv',\n",
       "  './all/s1/PMVC100-2sub01.csv',\n",
       "  './all/s1/PMVC100-3sub01.csv',\n",
       "  './all/s1/PMVC50-1sub01.csv',\n",
       "  './all/s1/PMVC75-1sub01.csv',\n",
       "  './all/s1/PMVCEXT100-1sub01.csv',\n",
       "  './all/s1/PMVCEXT100-2sub01.csv',\n",
       "  './all/s1/PMVCEXT100-3sub01.csv',\n",
       "  './all/s1/PMVCEXT25-1sub01.csv',\n",
       "  './all/s1/PMVCEXT50-1sub01.csv',\n",
       "  './all/s1/PMVCFLX100-1sub01.csv',\n",
       "  './all/s1/PMVCFLX100-2sub01.csv',\n",
       "  './all/s1/PMVCFLX100-3sub01.csv',\n",
       "  './all/s1/PMVCFLX25-1sub01.csv',\n",
       "  './all/s1/PMVCFLX50-1sub01.csv',\n",
       "  './all/s1/PMVCFLX75-1sub01.csv',\n",
       "  './all/s1/PMVCRD100-1sub01.csv',\n",
       "  './all/s1/PMVCRD100-2sub01.csv',\n",
       "  './all/s1/PMVCRD100-3sub01.csv',\n",
       "  './all/s1/PMVCRD25-1sub01.csv',\n",
       "  './all/s1/PMVCRD25-2sub01.csv',\n",
       "  './all/s1/PMVCRD50-1sub01.csv',\n",
       "  './all/s1/PMVCRD50-2sub01.csv',\n",
       "  './all/s1/PMVCRD75-1sub01.csv',\n",
       "  './all/s1/PMVCRD75-2sub01.csv',\n",
       "  './all/s1/PMVCUD100-1sub01.csv',\n",
       "  './all/s1/PMVCUD100-2sub01.csv',\n",
       "  './all/s1/PMVCUD100-3sub01.csv',\n",
       "  './all/s1/PMVCUD25-1sub01.csv',\n",
       "  './all/s1/PMVCUD25-2sub01.csv',\n",
       "  './all/s1/PMVCUD50-1sub01.csv',\n",
       "  './all/s1/PMVCUD50-2sub01.csv',\n",
       "  './all/s1/PMVCUD75-1sub01.csv',\n",
       "  './all/s1/PMVCUD75-2sub01.csv'],\n",
       " ['./all/s12/GMVCEXTENSION 100-37sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 100-39sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 100-41sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 25-43sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 25-45sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 50-47sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 50-49sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 75-51sub12.csv',\n",
       "  './all/s12/GMVCEXTENSION 75-53sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 100-19sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 100-21sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 100-23sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 25-25sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 25-27sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 50-29sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 50-31sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 75-33sub12.csv',\n",
       "  './all/s12/GMVCFLEXION 75-35sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 100-1sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 100-3sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 100-5sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 25-7sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 25-9sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 50-11sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 50-13sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 75-15sub12.csv',\n",
       "  './all/s12/GMVCNEUTRAL 75-17sub12.csv',\n",
       "  './all/s12/GMVCRD 100-55sub12.csv',\n",
       "  './all/s12/GMVCRD 100-57sub12.csv',\n",
       "  './all/s12/GMVCRD 25-59sub12.csv',\n",
       "  './all/s12/GMVCRD 25-61sub12.csv',\n",
       "  './all/s12/GMVCRD 50-63sub12.csv',\n",
       "  './all/s12/GMVCRD 50-65sub12.csv',\n",
       "  './all/s12/GMVCRD 75-67sub12.csv',\n",
       "  './all/s12/GMVCRD 75-69sub12.csv',\n",
       "  './all/s12/GMVCUD 100-71sub12.csv',\n",
       "  './all/s12/GMVCUD 100-73sub12.csv',\n",
       "  './all/s12/GMVCUD 100-75sub12.csv',\n",
       "  './all/s12/GMVCUD 25-77sub12.csv',\n",
       "  './all/s12/GMVCUD 25-79sub12.csv',\n",
       "  './all/s12/GMVCUD 50-81sub12.csv',\n",
       "  './all/s12/GMVCUD 50-83sub12.csv',\n",
       "  './all/s12/GMVCUD 75-85sub12.csv',\n",
       "  './all/s12/GMVCUD 75-87sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 100-35sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 100-37sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 100-39sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 25-41sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 25-43sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 50-45sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 50-47sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 75-49sub12.csv',\n",
       "  './all/s12/PMVCEXTENSION 75-51sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 100-19sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 100-21sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 25-23sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 25-25sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 50-27sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 50-29sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 75-31sub12.csv',\n",
       "  './all/s12/PMVCFLEXION 75-33sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 100-1sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 100-3sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 100-5sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 25-7sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 25-9sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 50-11sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 50-13sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 75-15sub12.csv',\n",
       "  './all/s12/PMVCNEUTRAL 75-17sub12.csv',\n",
       "  './all/s12/PMVCRD 100-53sub12.csv',\n",
       "  './all/s12/PMVCRD 100-55sub12.csv',\n",
       "  './all/s12/PMVCRD 25-57sub12.csv',\n",
       "  './all/s12/PMVCRD 25-59sub12.csv',\n",
       "  './all/s12/PMVCRD 50-61sub12.csv',\n",
       "  './all/s12/PMVCRD 50-63sub12.csv',\n",
       "  './all/s12/PMVCRD 75-65sub12.csv',\n",
       "  './all/s12/PMVCRD 75-67sub12.csv',\n",
       "  './all/s12/PMVCUD 100-69sub12.csv',\n",
       "  './all/s12/PMVCUD 100-71sub12.csv',\n",
       "  './all/s12/PMVCUD 100-73sub12.csv',\n",
       "  './all/s12/PMVCUD 25-75sub12.csv',\n",
       "  './all/s12/PMVCUD 25-77sub12.csv',\n",
       "  './all/s12/PMVCUD 50-79sub12.csv',\n",
       "  './all/s12/PMVCUD 50-81sub12.csv',\n",
       "  './all/s12/PMVCUD 75-83sub12.csv',\n",
       "  './all/s12/PMVCUD 75-85sub12.csv'],\n",
       " ['./all/s13/GMVCEXTENSION 100-1sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 100-3sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 100-5sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 25-7sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 25-9sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 50-11sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 50-13sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 75-15sub13.csv',\n",
       "  './all/s13/GMVCEXTENSION 75-17sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 100-19sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 100-21sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 100-23sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 25-25sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 25-27sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 50-29sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 75-31sub13.csv',\n",
       "  './all/s13/GMVCFLEXION 75-33sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 100-1sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 100-3sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 100-5sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 25-7sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 25-9sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 50-11sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 50-13sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 75-15sub13.csv',\n",
       "  './all/s13/GMVCNEUTRAL 75-17sub13.csv',\n",
       "  './all/s13/GMVCRD 100-19sub13.csv',\n",
       "  './all/s13/GMVCRD 100-21sub13.csv',\n",
       "  './all/s13/GMVCRD 100-23sub13.csv',\n",
       "  './all/s13/GMVCRD 25-25sub13.csv',\n",
       "  './all/s13/GMVCRD 25-27sub13.csv',\n",
       "  './all/s13/GMVCRD 50-29sub13.csv',\n",
       "  './all/s13/GMVCRD 50-31sub13.csv',\n",
       "  './all/s13/GMVCRD 75-33sub13.csv',\n",
       "  './all/s13/GMVCRD 75-35sub13.csv',\n",
       "  './all/s13/GMVCUD 100-37sub13.csv',\n",
       "  './all/s13/GMVCUD 100-39sub13.csv',\n",
       "  './all/s13/GMVCUD 100-41sub13.csv',\n",
       "  './all/s13/GMVCUD 25-43sub13.csv',\n",
       "  './all/s13/GMVCUD 25-45sub13.csv',\n",
       "  './all/s13/GMVCUD 50-47sub13.csv',\n",
       "  './all/s13/GMVCUD 50-49sub13.csv',\n",
       "  './all/s13/GMVCUD 75-51sub13.csv',\n",
       "  './all/s13/GMVCUD 75-53sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 100-37sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 25-43sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 25-45sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 50-47sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 50-49sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 75-51sub13.csv',\n",
       "  './all/s13/PMVCEXTENSION 75-53sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 100-19sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 100-21sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 100-23sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 100-39sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 100-41sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 25-25sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 25-27sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 50-29sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 50-31sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 75-33sub13.csv',\n",
       "  './all/s13/PMVCFLEXION 75-35sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 100-1sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 100-3sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 100-5sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 25-7sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 25-9sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 50-11sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 50-13sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 75-15sub13.csv',\n",
       "  './all/s13/PMVCNEUTRAL 75-17sub13.csv',\n",
       "  './all/s13/PMVCRD 100-57sub13.csv',\n",
       "  './all/s13/PMVCRD 100-59sub13.csv',\n",
       "  './all/s13/PMVCRD 25-61sub13.csv',\n",
       "  './all/s13/PMVCRD 25-63sub13.csv',\n",
       "  './all/s13/PMVCRD 50-65sub13.csv',\n",
       "  './all/s13/PMVCRD 50-67sub13.csv',\n",
       "  './all/s13/PMVCRD 75-69sub13.csv',\n",
       "  './all/s13/PMVCRD 75-71sub13.csv',\n",
       "  './all/s13/PMVCUD 100-73sub13.csv',\n",
       "  './all/s13/PMVCUD 100-75sub13.csv',\n",
       "  './all/s13/PMVCUD 100-77sub13.csv',\n",
       "  './all/s13/PMVCUD 25-79sub13.csv',\n",
       "  './all/s13/PMVCUD 25-81sub13.csv',\n",
       "  './all/s13/PMVCUD 50-83sub13.csv',\n",
       "  './all/s13/PMVCUD 50-85sub13.csv',\n",
       "  './all/s13/PMVCUD 75-87sub13.csv',\n",
       "  './all/s13/PMVCUD 75-89sub13.csv'],\n",
       " ['./all/s2/MVC100-1sub02.csv',\n",
       "  './all/s2/MVC100-2sub02.csv',\n",
       "  './all/s2/MVC100-3sub02.csv',\n",
       "  './all/s2/MVC25-1sub02.csv',\n",
       "  './all/s2/MVC25-2sub02.csv',\n",
       "  './all/s2/MVC50-1sub02.csv',\n",
       "  './all/s2/MVC50-2sub02.csv',\n",
       "  './all/s2/MVC75-1sub02.csv',\n",
       "  './all/s2/MVC75-2sub02.csv',\n",
       "  './all/s2/MVCEXT100-1sub02.csv',\n",
       "  './all/s2/MVCEXT100-2sub02.csv',\n",
       "  './all/s2/MVCEXT100-3sub02.csv',\n",
       "  './all/s2/MVCEXT25-1sub02.csv',\n",
       "  './all/s2/MVCEXT25-2sub02.csv',\n",
       "  './all/s2/MVCEXT50-1sub02.csv',\n",
       "  './all/s2/MVCEXT50-2sub02.csv',\n",
       "  './all/s2/MVCEXT75-1sub02.csv',\n",
       "  './all/s2/MVCEXT75-2sub02.csv',\n",
       "  './all/s2/MVCFLX100-1sub02.csv',\n",
       "  './all/s2/MVCFLX100-2sub02.csv',\n",
       "  './all/s2/MVCFLX100-3sub02.csv',\n",
       "  './all/s2/MVCFLX25-1sub02.csv',\n",
       "  './all/s2/MVCFLX25-2sub02.csv',\n",
       "  './all/s2/MVCFLX50-1sub02.csv',\n",
       "  './all/s2/MVCFLX50-2sub02.csv',\n",
       "  './all/s2/MVCFLX75-1sub02.csv',\n",
       "  './all/s2/MVCFLX75-2sub02.csv',\n",
       "  './all/s2/MVCRD100-1sub02.csv',\n",
       "  './all/s2/MVCRD100-2sub02.csv',\n",
       "  './all/s2/MVCRD100-3sub02.csv',\n",
       "  './all/s2/MVCRD25-1sub02.csv',\n",
       "  './all/s2/MVCRD25-2sub02.csv',\n",
       "  './all/s2/MVCRD50-1sub02.csv',\n",
       "  './all/s2/MVCRD50-2sub02.csv',\n",
       "  './all/s2/MVCRD75-1sub02.csv',\n",
       "  './all/s2/MVCRD75-2sub02.csv',\n",
       "  './all/s2/MVCUD100-1sub02.csv',\n",
       "  './all/s2/MVCUD100-2sub02.csv',\n",
       "  './all/s2/MVCUD100-3sub02.csv',\n",
       "  './all/s2/MVCUD25-1sub02.csv',\n",
       "  './all/s2/MVCUD25-2sub02.csv',\n",
       "  './all/s2/MVCUD50-1sub02.csv',\n",
       "  './all/s2/MVCUD50-2sub02.csv',\n",
       "  './all/s2/MVCUD75-1sub02.csv',\n",
       "  './all/s2/MVCUD75-2sub02.csv',\n",
       "  './all/s2/PMVC100-1sub02.csv',\n",
       "  './all/s2/PMVC100-2sub02.csv',\n",
       "  './all/s2/PMVC100-3sub02.csv',\n",
       "  './all/s2/PMVC25-1sub02.csv',\n",
       "  './all/s2/PMVC25-2sub02.csv',\n",
       "  './all/s2/PMVC50-1sub02.csv',\n",
       "  './all/s2/PMVC50-2sub02.csv',\n",
       "  './all/s2/PMVC75-1sub02.csv',\n",
       "  './all/s2/PMVC75-2sub02.csv',\n",
       "  './all/s2/PMVCEXT100-1sub02.csv',\n",
       "  './all/s2/PMVCEXT100-2sub02.csv',\n",
       "  './all/s2/PMVCEXT100-3sub02.csv',\n",
       "  './all/s2/PMVCEXT25-1sub02.csv',\n",
       "  './all/s2/PMVCEXT25-2sub02.csv',\n",
       "  './all/s2/PMVCEXT50-1sub02.csv',\n",
       "  './all/s2/PMVCEXT50-2sub02.csv',\n",
       "  './all/s2/PMVCEXT75-1sub02.csv',\n",
       "  './all/s2/PMVCEXT75-2sub02.csv',\n",
       "  './all/s2/PMVCFLX100-1sub02.csv',\n",
       "  './all/s2/PMVCFLX100-2sub02.csv',\n",
       "  './all/s2/PMVCFLX100-3sub02.csv',\n",
       "  './all/s2/PMVCFLX25-1sub02.csv',\n",
       "  './all/s2/PMVCFLX25-2sub02.csv',\n",
       "  './all/s2/PMVCFLX50-1sub02.csv',\n",
       "  './all/s2/PMVCFLX50-2sub02.csv',\n",
       "  './all/s2/PMVCFLX75-1sub02.csv',\n",
       "  './all/s2/PMVCFLX75-2sub02.csv',\n",
       "  './all/s2/PMVCRD100-1sub02.csv',\n",
       "  './all/s2/PMVCRD100-2sub02.csv',\n",
       "  './all/s2/PMVCRD100-3sub02.csv',\n",
       "  './all/s2/PMVCRD25-1sub02.csv',\n",
       "  './all/s2/PMVCRD25-2sub02.csv',\n",
       "  './all/s2/PMVCRD50-1sub02.csv',\n",
       "  './all/s2/PMVCRD50-2sub02.csv',\n",
       "  './all/s2/PMVCRD75-1sub02.csv',\n",
       "  './all/s2/PMVCRD75-2sub02.csv',\n",
       "  './all/s2/PMVCUD100-1sub02.csv',\n",
       "  './all/s2/PMVCUD100-2sub02.csv',\n",
       "  './all/s2/PMVCUD100-3sub02.csv',\n",
       "  './all/s2/PMVCUD25-1sub02.csv',\n",
       "  './all/s2/PMVCUD25-2sub02.csv',\n",
       "  './all/s2/PMVCUD50-1sub02.csv',\n",
       "  './all/s2/PMVCUD50-2sub02.csv',\n",
       "  './all/s2/PMVCUD75-1sub02.csv',\n",
       "  './all/s2/PMVCUD75-2sub02.csv'],\n",
       " ['./all/s3/MVC100-1sub03.csv',\n",
       "  './all/s3/MVC100-2sub03.csv',\n",
       "  './all/s3/MVC25-1sub03.csv',\n",
       "  './all/s3/MVC25-2sub03.csv',\n",
       "  './all/s3/MVC50-1sub03.csv',\n",
       "  './all/s3/MVC50-2sub03.csv',\n",
       "  './all/s3/MVC75-1sub03.csv',\n",
       "  './all/s3/MVC75-2sub03.csv',\n",
       "  './all/s3/MVCEXT100-1sub03.csv',\n",
       "  './all/s3/MVCEXT100-2sub03.csv',\n",
       "  './all/s3/MVCEXT25-1sub03.csv',\n",
       "  './all/s3/MVCEXT25-2sub03.csv',\n",
       "  './all/s3/MVCEXT50-1sub03.csv',\n",
       "  './all/s3/MVCEXT50-2sub03.csv',\n",
       "  './all/s3/MVCEXT75-1sub03.csv',\n",
       "  './all/s3/MVCFLX100-1sub03.csv',\n",
       "  './all/s3/MVCFLX100-2sub03.csv',\n",
       "  './all/s3/MVCFLX25-1sub03.csv',\n",
       "  './all/s3/MVCFLX25-2sub03.csv',\n",
       "  './all/s3/MVCFLX50-1sub03.csv',\n",
       "  './all/s3/MVCFLX50-2sub03.csv',\n",
       "  './all/s3/MVCFLX75-1sub03.csv',\n",
       "  './all/s3/MVCFLX75-2sub03.csv',\n",
       "  './all/s3/MVCRD100-1sub03.csv',\n",
       "  './all/s3/MVCRD100-2sub03.csv',\n",
       "  './all/s3/MVCRD25-1sub03.csv',\n",
       "  './all/s3/MVCRD25-2sub03.csv',\n",
       "  './all/s3/MVCRD50-1sub03.csv',\n",
       "  './all/s3/MVCRD50-2sub03.csv',\n",
       "  './all/s3/MVCRD75-1sub03.csv',\n",
       "  './all/s3/MVCRD75-2sub03.csv',\n",
       "  './all/s3/MVCUD100-1sub03.csv',\n",
       "  './all/s3/MVCUD100-2sub03.csv',\n",
       "  './all/s3/MVCUD25-1sub03.csv',\n",
       "  './all/s3/MVCUD25-2sub03.csv',\n",
       "  './all/s3/MVCUD50-1sub03.csv',\n",
       "  './all/s3/MVCUD50-2sub03.csv',\n",
       "  './all/s3/MVCUD75-1sub03.csv',\n",
       "  './all/s3/MVCUD75-2sub03.csv',\n",
       "  './all/s3/PMVC100-1sub03.csv',\n",
       "  './all/s3/PMVC100-2sub03.csv',\n",
       "  './all/s3/PMVC25-1sub03.csv',\n",
       "  './all/s3/PMVC25-2sub03.csv',\n",
       "  './all/s3/PMVC50-1sub03.csv',\n",
       "  './all/s3/PMVC50-2sub03.csv',\n",
       "  './all/s3/PMVC75-1sub03.csv',\n",
       "  './all/s3/PMVC75-2sub03.csv',\n",
       "  './all/s3/PMVCEXT100-1sub03.csv',\n",
       "  './all/s3/PMVCEXT100-2sub03.csv',\n",
       "  './all/s3/PMVCEXT25-1sub03.csv',\n",
       "  './all/s3/PMVCEXT25-2sub03.csv',\n",
       "  './all/s3/PMVCEXT50-2sub03.csv',\n",
       "  './all/s3/PMVCEXT75-1sub03.csv',\n",
       "  './all/s3/PMVCEXT75-2sub03.csv',\n",
       "  './all/s3/PMVCFLX100-1sub03.csv',\n",
       "  './all/s3/PMVCFLX100-2sub03.csv',\n",
       "  './all/s3/PMVCFLX25-1sub03.csv',\n",
       "  './all/s3/PMVCFLX25-2sub03.csv',\n",
       "  './all/s3/PMVCFLX50-1sub03.csv',\n",
       "  './all/s3/PMVCFLX75-1sub03.csv',\n",
       "  './all/s3/PMVCFLX75-2sub03.csv',\n",
       "  './all/s3/PMVCRD100-1sub03.csv',\n",
       "  './all/s3/PMVCRD100-2sub03.csv',\n",
       "  './all/s3/PMVCRD25-1sub03.csv',\n",
       "  './all/s3/PMVCRD25-2sub03.csv',\n",
       "  './all/s3/PMVCRD50-1sub03.csv',\n",
       "  './all/s3/PMVCRD50-2sub03.csv',\n",
       "  './all/s3/PMVCRD75-1sub03.csv',\n",
       "  './all/s3/PMVCRD75-2sub03.csv',\n",
       "  './all/s3/PMVCUD100-1sub03.csv',\n",
       "  './all/s3/PMVCUD100-2sub03.csv',\n",
       "  './all/s3/PMVCUD25-1sub03.csv',\n",
       "  './all/s3/PMVCUD25-2sub03.csv',\n",
       "  './all/s3/PMVCUD50-1sub03.csv',\n",
       "  './all/s3/PMVCUD50-2sub03.csv',\n",
       "  './all/s3/PMVCUD75-1sub03.csv',\n",
       "  './all/s3/PMVCUD75-2sub03.csv']]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = \"./all\"\n",
    "file = []\n",
    "\n",
    "for d in sorted(os.listdir(directory)):\n",
    "    if d != '.DS_Store':\n",
    "        files = directory + '/' + d\n",
    "        name = []\n",
    "        for f in sorted(os.listdir(files)):\n",
    "            name.append(files + \"/\" + f)\n",
    "        file.append(name)\n",
    "        print(\"%s number of activity: %s\" %(d, len(name)))\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  ./all/s1/MVC100-1sub01.csv\n",
      "processing:  ./all/s1/MVC100-2sub01.csv\n",
      "processing:  ./all/s1/MVC100-3sub01.csv\n",
      "processing:  ./all/s1/MVC25-1sub01.csv\n",
      "processing:  ./all/s1/MVC25-2sub01.csv\n",
      "processing:  ./all/s1/MVC50-1sub01.csv\n",
      "processing:  ./all/s1/MVC50-2sub01.csv\n",
      "processing:  ./all/s1/MVC75-1sub01.csv\n",
      "processing:  ./all/s1/MVC75-2sub01.csv\n",
      "processing:  ./all/s1/MVCEXT100-1sub01.csv\n",
      "processing:  ./all/s1/MVCEXT100-2sub01.csv\n",
      "processing:  ./all/s1/MVCEXT100-3sub01.csv\n",
      "processing:  ./all/s1/MVCEXT25-1sub01.csv\n",
      "processing:  ./all/s1/MVCEXT25-2sub01.csv\n",
      "processing:  ./all/s1/MVCEXT50-1sub01.csv\n",
      "processing:  ./all/s1/MVCEXT50-2sub01.csv\n",
      "processing:  ./all/s1/MVCEXT75-1sub01.csv\n",
      "processing:  ./all/s1/MVCEXT75-2sub01.csv\n",
      "processing:  ./all/s1/MVCFLX100-1sub01.csv\n",
      "processing:  ./all/s1/MVCFLX100-2sub01.csv\n",
      "processing:  ./all/s1/MVCFLX100-3sub01.csv\n",
      "processing:  ./all/s1/MVCFLX25-1sub01.csv\n",
      "processing:  ./all/s1/MVCFLX25-2sub01.csv\n",
      "processing:  ./all/s1/MVCFLX50-1sub01.csv\n",
      "processing:  ./all/s1/MVCFLX50-2sub01.csv\n",
      "processing:  ./all/s1/MVCFLX75-1sub01.csv\n",
      "processing:  ./all/s1/MVCFLX75-2sub01.csv\n",
      "processing:  ./all/s1/MVCRD100-1sub01.csv\n",
      "processing:  ./all/s1/MVCRD100-2sub01.csv\n",
      "processing:  ./all/s1/MVCRD100-3sub01.csv\n",
      "processing:  ./all/s1/MVCRD25-1sub01.csv\n",
      "processing:  ./all/s1/MVCRD25-2sub01.csv\n",
      "processing:  ./all/s1/MVCRD50-1sub01.csv\n",
      "processing:  ./all/s1/MVCRD50-2sub01.csv\n",
      "processing:  ./all/s1/MVCRD75-1sub01.csv\n",
      "processing:  ./all/s1/MVCRD75-2sub01.csv\n",
      "processing:  ./all/s1/MVCUD100-1sub01.csv\n",
      "processing:  ./all/s1/MVCUD100-2sub01.csv\n",
      "processing:  ./all/s1/MVCUD100-3sub01.csv\n",
      "processing:  ./all/s1/MVCUD25-1sub01.csv\n",
      "processing:  ./all/s1/MVCUD25-2sub01.csv\n",
      "processing:  ./all/s1/MVCUD50-1sub01.csv\n",
      "processing:  ./all/s1/MVCUD50-2sub01.csv\n",
      "processing:  ./all/s1/MVCUD75-1sub01.csv\n",
      "processing:  ./all/s1/MVCUD75-2sub01.csv\n",
      "processing:  ./all/s1/PMVC100-1sub01.csv\n",
      "processing:  ./all/s1/PMVC100-2sub01.csv\n",
      "processing:  ./all/s1/PMVC100-3sub01.csv\n",
      "processing:  ./all/s1/PMVC50-1sub01.csv\n",
      "processing:  ./all/s1/PMVC75-1sub01.csv\n",
      "processing:  ./all/s1/PMVCEXT100-1sub01.csv\n",
      "processing:  ./all/s1/PMVCEXT100-2sub01.csv\n",
      "processing:  ./all/s1/PMVCEXT100-3sub01.csv\n",
      "processing:  ./all/s1/PMVCEXT25-1sub01.csv\n",
      "processing:  ./all/s1/PMVCEXT50-1sub01.csv\n",
      "processing:  ./all/s1/PMVCFLX100-1sub01.csv\n",
      "processing:  ./all/s1/PMVCFLX100-2sub01.csv\n",
      "processing:  ./all/s1/PMVCFLX100-3sub01.csv\n",
      "processing:  ./all/s1/PMVCFLX25-1sub01.csv\n",
      "processing:  ./all/s1/PMVCFLX50-1sub01.csv\n",
      "processing:  ./all/s1/PMVCFLX75-1sub01.csv\n",
      "processing:  ./all/s1/PMVCRD100-1sub01.csv\n",
      "processing:  ./all/s1/PMVCRD100-2sub01.csv\n",
      "processing:  ./all/s1/PMVCRD100-3sub01.csv\n",
      "processing:  ./all/s1/PMVCRD25-1sub01.csv\n",
      "processing:  ./all/s1/PMVCRD25-2sub01.csv\n",
      "processing:  ./all/s1/PMVCRD50-1sub01.csv\n",
      "processing:  ./all/s1/PMVCRD50-2sub01.csv\n",
      "processing:  ./all/s1/PMVCRD75-1sub01.csv\n",
      "processing:  ./all/s1/PMVCRD75-2sub01.csv\n",
      "processing:  ./all/s1/PMVCUD100-1sub01.csv\n",
      "processing:  ./all/s1/PMVCUD100-2sub01.csv\n",
      "processing:  ./all/s1/PMVCUD100-3sub01.csv\n",
      "processing:  ./all/s1/PMVCUD25-1sub01.csv\n",
      "processing:  ./all/s1/PMVCUD25-2sub01.csv\n",
      "processing:  ./all/s1/PMVCUD50-1sub01.csv\n",
      "processing:  ./all/s1/PMVCUD50-2sub01.csv\n",
      "processing:  ./all/s1/PMVCUD75-1sub01.csv\n",
      "processing:  ./all/s1/PMVCUD75-2sub01.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 100-37sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 100-39sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 100-41sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 25-43sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 25-45sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 50-47sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 50-49sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 75-51sub12.csv\n",
      "processing:  ./all/s12/GMVCEXTENSION 75-53sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 100-19sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 100-21sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 100-23sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 25-25sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 25-27sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 50-29sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 50-31sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 75-33sub12.csv\n",
      "processing:  ./all/s12/GMVCFLEXION 75-35sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 100-1sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 100-3sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 100-5sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 25-7sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 25-9sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 50-11sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 50-13sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 75-15sub12.csv\n",
      "processing:  ./all/s12/GMVCNEUTRAL 75-17sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 100-55sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 100-57sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 25-59sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 25-61sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 50-63sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 50-65sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 75-67sub12.csv\n",
      "processing:  ./all/s12/GMVCRD 75-69sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 100-71sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 100-73sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 100-75sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 25-77sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 25-79sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 50-81sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 50-83sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 75-85sub12.csv\n",
      "processing:  ./all/s12/GMVCUD 75-87sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 100-35sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 100-37sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 100-39sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 25-41sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 25-43sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 50-45sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 50-47sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 75-49sub12.csv\n",
      "processing:  ./all/s12/PMVCEXTENSION 75-51sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 100-19sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 100-21sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 25-23sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 25-25sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 50-27sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 50-29sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 75-31sub12.csv\n",
      "processing:  ./all/s12/PMVCFLEXION 75-33sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 100-1sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 100-3sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 100-5sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 25-7sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 25-9sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 50-11sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 50-13sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 75-15sub12.csv\n",
      "processing:  ./all/s12/PMVCNEUTRAL 75-17sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 100-53sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 100-55sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 25-57sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 25-59sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 50-61sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 50-63sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 75-65sub12.csv\n",
      "processing:  ./all/s12/PMVCRD 75-67sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 100-69sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 100-71sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 100-73sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 25-75sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 25-77sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 50-79sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 50-81sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 75-83sub12.csv\n",
      "processing:  ./all/s12/PMVCUD 75-85sub12.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 100-1sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 100-3sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 100-5sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 25-7sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 25-9sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 50-11sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 50-13sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 75-15sub13.csv\n",
      "processing:  ./all/s13/GMVCEXTENSION 75-17sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 100-19sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 100-21sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 100-23sub13.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  ./all/s13/GMVCFLEXION 25-25sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 25-27sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 50-29sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 75-31sub13.csv\n",
      "processing:  ./all/s13/GMVCFLEXION 75-33sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 100-1sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 100-3sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 100-5sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 25-7sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 25-9sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 50-11sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 50-13sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 75-15sub13.csv\n",
      "processing:  ./all/s13/GMVCNEUTRAL 75-17sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 100-19sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 100-21sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 100-23sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 25-25sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 25-27sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 50-29sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 50-31sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 75-33sub13.csv\n",
      "processing:  ./all/s13/GMVCRD 75-35sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 100-37sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 100-39sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 100-41sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 25-43sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 25-45sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 50-47sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 50-49sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 75-51sub13.csv\n",
      "processing:  ./all/s13/GMVCUD 75-53sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 100-37sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 25-43sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 25-45sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 50-47sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 50-49sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 75-51sub13.csv\n",
      "processing:  ./all/s13/PMVCEXTENSION 75-53sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 100-19sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 100-21sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 100-23sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 100-39sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 100-41sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 25-25sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 25-27sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 50-29sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 50-31sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 75-33sub13.csv\n",
      "processing:  ./all/s13/PMVCFLEXION 75-35sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 100-1sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 100-3sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 100-5sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 25-7sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 25-9sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 50-11sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 50-13sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 75-15sub13.csv\n",
      "processing:  ./all/s13/PMVCNEUTRAL 75-17sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 100-57sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 100-59sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 25-61sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 25-63sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 50-65sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 50-67sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 75-69sub13.csv\n",
      "processing:  ./all/s13/PMVCRD 75-71sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 100-73sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 100-75sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 100-77sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 25-79sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 25-81sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 50-83sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 50-85sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 75-87sub13.csv\n",
      "processing:  ./all/s13/PMVCUD 75-89sub13.csv\n",
      "processing:  ./all/s2/MVC100-1sub02.csv\n",
      "processing:  ./all/s2/MVC100-2sub02.csv\n",
      "processing:  ./all/s2/MVC100-3sub02.csv\n",
      "processing:  ./all/s2/MVC25-1sub02.csv\n",
      "processing:  ./all/s2/MVC25-2sub02.csv\n",
      "processing:  ./all/s2/MVC50-1sub02.csv\n",
      "processing:  ./all/s2/MVC50-2sub02.csv\n",
      "processing:  ./all/s2/MVC75-1sub02.csv\n",
      "processing:  ./all/s2/MVC75-2sub02.csv\n",
      "processing:  ./all/s2/MVCEXT100-1sub02.csv\n",
      "processing:  ./all/s2/MVCEXT100-2sub02.csv\n",
      "processing:  ./all/s2/MVCEXT100-3sub02.csv\n",
      "processing:  ./all/s2/MVCEXT25-1sub02.csv\n",
      "processing:  ./all/s2/MVCEXT25-2sub02.csv\n",
      "processing:  ./all/s2/MVCEXT50-1sub02.csv\n",
      "processing:  ./all/s2/MVCEXT50-2sub02.csv\n",
      "processing:  ./all/s2/MVCEXT75-1sub02.csv\n",
      "processing:  ./all/s2/MVCEXT75-2sub02.csv\n",
      "processing:  ./all/s2/MVCFLX100-1sub02.csv\n",
      "processing:  ./all/s2/MVCFLX100-2sub02.csv\n",
      "processing:  ./all/s2/MVCFLX100-3sub02.csv\n",
      "processing:  ./all/s2/MVCFLX25-1sub02.csv\n",
      "processing:  ./all/s2/MVCFLX25-2sub02.csv\n",
      "processing:  ./all/s2/MVCFLX50-1sub02.csv\n",
      "processing:  ./all/s2/MVCFLX50-2sub02.csv\n",
      "processing:  ./all/s2/MVCFLX75-1sub02.csv\n",
      "processing:  ./all/s2/MVCFLX75-2sub02.csv\n",
      "processing:  ./all/s2/MVCRD100-1sub02.csv\n",
      "processing:  ./all/s2/MVCRD100-2sub02.csv\n",
      "processing:  ./all/s2/MVCRD100-3sub02.csv\n",
      "processing:  ./all/s2/MVCRD25-1sub02.csv\n",
      "processing:  ./all/s2/MVCRD25-2sub02.csv\n",
      "processing:  ./all/s2/MVCRD50-1sub02.csv\n",
      "processing:  ./all/s2/MVCRD50-2sub02.csv\n",
      "processing:  ./all/s2/MVCRD75-1sub02.csv\n",
      "processing:  ./all/s2/MVCRD75-2sub02.csv\n",
      "processing:  ./all/s2/MVCUD100-1sub02.csv\n",
      "processing:  ./all/s2/MVCUD100-2sub02.csv\n",
      "processing:  ./all/s2/MVCUD100-3sub02.csv\n",
      "processing:  ./all/s2/MVCUD25-1sub02.csv\n",
      "processing:  ./all/s2/MVCUD25-2sub02.csv\n",
      "processing:  ./all/s2/MVCUD50-1sub02.csv\n",
      "processing:  ./all/s2/MVCUD50-2sub02.csv\n",
      "processing:  ./all/s2/MVCUD75-1sub02.csv\n",
      "processing:  ./all/s2/MVCUD75-2sub02.csv\n",
      "processing:  ./all/s2/PMVC100-1sub02.csv\n",
      "processing:  ./all/s2/PMVC100-2sub02.csv\n",
      "processing:  ./all/s2/PMVC100-3sub02.csv\n",
      "processing:  ./all/s2/PMVC25-1sub02.csv\n",
      "processing:  ./all/s2/PMVC25-2sub02.csv\n",
      "processing:  ./all/s2/PMVC50-1sub02.csv\n",
      "processing:  ./all/s2/PMVC50-2sub02.csv\n",
      "processing:  ./all/s2/PMVC75-1sub02.csv\n",
      "processing:  ./all/s2/PMVC75-2sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT100-1sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT100-2sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT100-3sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT25-1sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT25-2sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT50-1sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT50-2sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT75-1sub02.csv\n",
      "processing:  ./all/s2/PMVCEXT75-2sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX100-1sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX100-2sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX100-3sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX25-1sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX25-2sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX50-1sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX50-2sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX75-1sub02.csv\n",
      "processing:  ./all/s2/PMVCFLX75-2sub02.csv\n",
      "processing:  ./all/s2/PMVCRD100-1sub02.csv\n",
      "processing:  ./all/s2/PMVCRD100-2sub02.csv\n",
      "processing:  ./all/s2/PMVCRD100-3sub02.csv\n",
      "processing:  ./all/s2/PMVCRD25-1sub02.csv\n",
      "processing:  ./all/s2/PMVCRD25-2sub02.csv\n",
      "processing:  ./all/s2/PMVCRD50-1sub02.csv\n",
      "processing:  ./all/s2/PMVCRD50-2sub02.csv\n",
      "processing:  ./all/s2/PMVCRD75-1sub02.csv\n",
      "processing:  ./all/s2/PMVCRD75-2sub02.csv\n",
      "processing:  ./all/s2/PMVCUD100-1sub02.csv\n",
      "processing:  ./all/s2/PMVCUD100-2sub02.csv\n",
      "processing:  ./all/s2/PMVCUD100-3sub02.csv\n",
      "processing:  ./all/s2/PMVCUD25-1sub02.csv\n",
      "processing:  ./all/s2/PMVCUD25-2sub02.csv\n",
      "processing:  ./all/s2/PMVCUD50-1sub02.csv\n",
      "processing:  ./all/s2/PMVCUD50-2sub02.csv\n",
      "processing:  ./all/s2/PMVCUD75-1sub02.csv\n",
      "processing:  ./all/s2/PMVCUD75-2sub02.csv\n",
      "processing:  ./all/s3/MVC100-1sub03.csv\n",
      "processing:  ./all/s3/MVC100-2sub03.csv\n",
      "processing:  ./all/s3/MVC25-1sub03.csv\n",
      "processing:  ./all/s3/MVC25-2sub03.csv\n",
      "processing:  ./all/s3/MVC50-1sub03.csv\n",
      "processing:  ./all/s3/MVC50-2sub03.csv\n",
      "processing:  ./all/s3/MVC75-1sub03.csv\n",
      "processing:  ./all/s3/MVC75-2sub03.csv\n",
      "processing:  ./all/s3/MVCEXT100-1sub03.csv\n",
      "processing:  ./all/s3/MVCEXT100-2sub03.csv\n",
      "processing:  ./all/s3/MVCEXT25-1sub03.csv\n",
      "processing:  ./all/s3/MVCEXT25-2sub03.csv\n",
      "processing:  ./all/s3/MVCEXT50-1sub03.csv\n",
      "processing:  ./all/s3/MVCEXT50-2sub03.csv\n",
      "processing:  ./all/s3/MVCEXT75-1sub03.csv\n",
      "processing:  ./all/s3/MVCFLX100-1sub03.csv\n",
      "processing:  ./all/s3/MVCFLX100-2sub03.csv\n",
      "processing:  ./all/s3/MVCFLX25-1sub03.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  ./all/s3/MVCFLX25-2sub03.csv\n",
      "processing:  ./all/s3/MVCFLX50-1sub03.csv\n",
      "processing:  ./all/s3/MVCFLX50-2sub03.csv\n",
      "processing:  ./all/s3/MVCFLX75-1sub03.csv\n",
      "processing:  ./all/s3/MVCFLX75-2sub03.csv\n",
      "processing:  ./all/s3/MVCRD100-1sub03.csv\n",
      "processing:  ./all/s3/MVCRD100-2sub03.csv\n",
      "processing:  ./all/s3/MVCRD25-1sub03.csv\n",
      "processing:  ./all/s3/MVCRD25-2sub03.csv\n",
      "processing:  ./all/s3/MVCRD50-1sub03.csv\n",
      "processing:  ./all/s3/MVCRD50-2sub03.csv\n",
      "processing:  ./all/s3/MVCRD75-1sub03.csv\n",
      "processing:  ./all/s3/MVCRD75-2sub03.csv\n",
      "processing:  ./all/s3/MVCUD100-1sub03.csv\n",
      "processing:  ./all/s3/MVCUD100-2sub03.csv\n",
      "processing:  ./all/s3/MVCUD25-1sub03.csv\n",
      "processing:  ./all/s3/MVCUD25-2sub03.csv\n",
      "processing:  ./all/s3/MVCUD50-1sub03.csv\n",
      "processing:  ./all/s3/MVCUD50-2sub03.csv\n",
      "processing:  ./all/s3/MVCUD75-1sub03.csv\n",
      "processing:  ./all/s3/MVCUD75-2sub03.csv\n",
      "processing:  ./all/s3/PMVC100-1sub03.csv\n",
      "processing:  ./all/s3/PMVC100-2sub03.csv\n",
      "processing:  ./all/s3/PMVC25-1sub03.csv\n",
      "processing:  ./all/s3/PMVC25-2sub03.csv\n",
      "processing:  ./all/s3/PMVC50-1sub03.csv\n",
      "processing:  ./all/s3/PMVC50-2sub03.csv\n",
      "processing:  ./all/s3/PMVC75-1sub03.csv\n",
      "processing:  ./all/s3/PMVC75-2sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT100-1sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT100-2sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT25-1sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT25-2sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT50-2sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT75-1sub03.csv\n",
      "processing:  ./all/s3/PMVCEXT75-2sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX100-1sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX100-2sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX25-1sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX25-2sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX50-1sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX75-1sub03.csv\n",
      "processing:  ./all/s3/PMVCFLX75-2sub03.csv\n",
      "processing:  ./all/s3/PMVCRD100-1sub03.csv\n",
      "processing:  ./all/s3/PMVCRD100-2sub03.csv\n",
      "processing:  ./all/s3/PMVCRD25-1sub03.csv\n",
      "processing:  ./all/s3/PMVCRD25-2sub03.csv\n",
      "processing:  ./all/s3/PMVCRD50-1sub03.csv\n",
      "processing:  ./all/s3/PMVCRD50-2sub03.csv\n",
      "processing:  ./all/s3/PMVCRD75-1sub03.csv\n",
      "processing:  ./all/s3/PMVCRD75-2sub03.csv\n",
      "processing:  ./all/s3/PMVCUD100-1sub03.csv\n",
      "processing:  ./all/s3/PMVCUD100-2sub03.csv\n",
      "processing:  ./all/s3/PMVCUD25-1sub03.csv\n",
      "processing:  ./all/s3/PMVCUD25-2sub03.csv\n",
      "processing:  ./all/s3/PMVCUD50-1sub03.csv\n",
      "processing:  ./all/s3/PMVCUD50-2sub03.csv\n",
      "processing:  ./all/s3/PMVCUD75-1sub03.csv\n",
      "processing:  ./all/s3/PMVCUD75-2sub03.csv\n"
     ]
    }
   ],
   "source": [
    "frame = []\n",
    "count = 0\n",
    "for person in file:\n",
    "    for file_path in person:\n",
    "        if count < 3000:\n",
    "            print(\"processing: \", file_path)\n",
    "            df = pd.read_csv(file_path, error_bad_lines=False)\n",
    "    #         df.columns = header\n",
    "            frame.append(df)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "            # mkdir if not exist. Save to local csv file\n",
    "#             if not (os.path.exists('./Spinetrack Data/Yibin_Processed/' + category + folder_name)):\n",
    "#                 os.makedirs('./Spinetrack Data/Yibin_Processed/' + category + folder_name)\n",
    "#             csv_name = '/' + activity_name + '.csv'\n",
    "#             folder_name = file_path.split(\"/\")[-3] # person's name \n",
    "#             category = 'data/' # data or task\n",
    "#             file_name = './Spinetrack Data/Yibin_Processed/' + category + folder_name + csv_name\n",
    "#             df.to_csv(file_name) # save csv processed file to local\n",
    "            \n",
    "            #print(file_path)\n",
    "data_df = pd.concat(frame)\n",
    "result_df = data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED</th>\n",
       "      <th>ECU</th>\n",
       "      <th>FCU</th>\n",
       "      <th>FD</th>\n",
       "      <th>APL</th>\n",
       "      <th>Force</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.438920</td>\n",
       "      <td>1.699614</td>\n",
       "      <td>5.369880</td>\n",
       "      <td>1.410052</td>\n",
       "      <td>5.872086</td>\n",
       "      <td>0.417777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.444880</td>\n",
       "      <td>1.705788</td>\n",
       "      <td>5.466240</td>\n",
       "      <td>1.410052</td>\n",
       "      <td>5.979987</td>\n",
       "      <td>0.411065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.450840</td>\n",
       "      <td>1.724604</td>\n",
       "      <td>5.553840</td>\n",
       "      <td>1.410052</td>\n",
       "      <td>6.076530</td>\n",
       "      <td>0.414705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.462760</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>5.575740</td>\n",
       "      <td>1.410052</td>\n",
       "      <td>6.121962</td>\n",
       "      <td>0.414568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.489580</td>\n",
       "      <td>1.755768</td>\n",
       "      <td>5.615160</td>\n",
       "      <td>1.419298</td>\n",
       "      <td>6.303690</td>\n",
       "      <td>0.413104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.519380</td>\n",
       "      <td>1.768116</td>\n",
       "      <td>5.689620</td>\n",
       "      <td>1.447671</td>\n",
       "      <td>6.621714</td>\n",
       "      <td>0.414177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.537260</td>\n",
       "      <td>1.774290</td>\n",
       "      <td>5.724660</td>\n",
       "      <td>1.456916</td>\n",
       "      <td>6.848874</td>\n",
       "      <td>0.414065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.564080</td>\n",
       "      <td>1.793106</td>\n",
       "      <td>5.750940</td>\n",
       "      <td>1.456916</td>\n",
       "      <td>6.928380</td>\n",
       "      <td>0.413938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.620700</td>\n",
       "      <td>1.799280</td>\n",
       "      <td>5.821020</td>\n",
       "      <td>1.484970</td>\n",
       "      <td>6.979491</td>\n",
       "      <td>0.413693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.719040</td>\n",
       "      <td>1.818096</td>\n",
       "      <td>5.921760</td>\n",
       "      <td>1.503780</td>\n",
       "      <td>7.104429</td>\n",
       "      <td>0.413783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.799500</td>\n",
       "      <td>1.818096</td>\n",
       "      <td>6.009360</td>\n",
       "      <td>1.522589</td>\n",
       "      <td>7.189614</td>\n",
       "      <td>0.414913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.850160</td>\n",
       "      <td>1.818096</td>\n",
       "      <td>6.079440</td>\n",
       "      <td>1.569771</td>\n",
       "      <td>7.189614</td>\n",
       "      <td>0.412784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.909760</td>\n",
       "      <td>1.830444</td>\n",
       "      <td>6.153900</td>\n",
       "      <td>1.645008</td>\n",
       "      <td>7.240725</td>\n",
       "      <td>0.413404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.966380</td>\n",
       "      <td>1.842792</td>\n",
       "      <td>6.250260</td>\n",
       "      <td>1.682626</td>\n",
       "      <td>7.286157</td>\n",
       "      <td>0.417892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.017040</td>\n",
       "      <td>1.867782</td>\n",
       "      <td>6.377280</td>\n",
       "      <td>1.682626</td>\n",
       "      <td>7.314552</td>\n",
       "      <td>0.406873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.079620</td>\n",
       "      <td>1.905120</td>\n",
       "      <td>6.552480</td>\n",
       "      <td>1.691872</td>\n",
       "      <td>7.325910</td>\n",
       "      <td>0.385446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.133260</td>\n",
       "      <td>1.948632</td>\n",
       "      <td>6.710160</td>\n",
       "      <td>1.720245</td>\n",
       "      <td>7.331589</td>\n",
       "      <td>0.380451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.139220</td>\n",
       "      <td>2.004786</td>\n",
       "      <td>6.815280</td>\n",
       "      <td>1.748299</td>\n",
       "      <td>7.399737</td>\n",
       "      <td>0.385654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.154120</td>\n",
       "      <td>2.060646</td>\n",
       "      <td>6.902880</td>\n",
       "      <td>1.767108</td>\n",
       "      <td>7.530354</td>\n",
       "      <td>0.384344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.228620</td>\n",
       "      <td>2.091810</td>\n",
       "      <td>7.003620</td>\n",
       "      <td>1.795163</td>\n",
       "      <td>7.643934</td>\n",
       "      <td>0.382899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.297160</td>\n",
       "      <td>2.116800</td>\n",
       "      <td>7.130640</td>\n",
       "      <td>1.823536</td>\n",
       "      <td>7.729119</td>\n",
       "      <td>0.384362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.326960</td>\n",
       "      <td>2.154138</td>\n",
       "      <td>7.292700</td>\n",
       "      <td>1.842345</td>\n",
       "      <td>7.808625</td>\n",
       "      <td>0.384245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.356760</td>\n",
       "      <td>2.172954</td>\n",
       "      <td>7.450380</td>\n",
       "      <td>1.964446</td>\n",
       "      <td>7.854057</td>\n",
       "      <td>0.383811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.446160</td>\n",
       "      <td>2.185302</td>\n",
       "      <td>7.586160</td>\n",
       "      <td>2.152538</td>\n",
       "      <td>7.905168</td>\n",
       "      <td>0.383533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.550460</td>\n",
       "      <td>2.203824</td>\n",
       "      <td>7.735080</td>\n",
       "      <td>2.293447</td>\n",
       "      <td>8.047143</td>\n",
       "      <td>0.384271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.586220</td>\n",
       "      <td>2.216466</td>\n",
       "      <td>7.892760</td>\n",
       "      <td>2.368684</td>\n",
       "      <td>8.143686</td>\n",
       "      <td>0.384630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.607080</td>\n",
       "      <td>2.228814</td>\n",
       "      <td>8.050440</td>\n",
       "      <td>2.406302</td>\n",
       "      <td>8.268624</td>\n",
       "      <td>0.382328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.669660</td>\n",
       "      <td>2.234988</td>\n",
       "      <td>8.194980</td>\n",
       "      <td>2.434357</td>\n",
       "      <td>8.478747</td>\n",
       "      <td>0.384667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.768000</td>\n",
       "      <td>2.241456</td>\n",
       "      <td>8.300100</td>\n",
       "      <td>2.434357</td>\n",
       "      <td>8.586648</td>\n",
       "      <td>0.386576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.854420</td>\n",
       "      <td>2.241456</td>\n",
       "      <td>8.322000</td>\n",
       "      <td>2.443921</td>\n",
       "      <td>8.677512</td>\n",
       "      <td>0.374676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953816</th>\n",
       "      <td>10.974003</td>\n",
       "      <td>5.345788</td>\n",
       "      <td>5.348306</td>\n",
       "      <td>7.268773</td>\n",
       "      <td>8.838026</td>\n",
       "      <td>0.040024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953817</th>\n",
       "      <td>11.066416</td>\n",
       "      <td>5.345788</td>\n",
       "      <td>5.285343</td>\n",
       "      <td>7.305905</td>\n",
       "      <td>8.748374</td>\n",
       "      <td>0.039451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953818</th>\n",
       "      <td>11.089519</td>\n",
       "      <td>5.345788</td>\n",
       "      <td>5.253862</td>\n",
       "      <td>7.336850</td>\n",
       "      <td>8.662891</td>\n",
       "      <td>0.039885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953819</th>\n",
       "      <td>11.158828</td>\n",
       "      <td>5.345788</td>\n",
       "      <td>5.236372</td>\n",
       "      <td>7.361605</td>\n",
       "      <td>8.646212</td>\n",
       "      <td>0.040024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953820</th>\n",
       "      <td>11.315930</td>\n",
       "      <td>5.376124</td>\n",
       "      <td>5.232875</td>\n",
       "      <td>7.364699</td>\n",
       "      <td>8.662891</td>\n",
       "      <td>0.039176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953821</th>\n",
       "      <td>11.385239</td>\n",
       "      <td>5.376124</td>\n",
       "      <td>5.229377</td>\n",
       "      <td>7.312094</td>\n",
       "      <td>8.717100</td>\n",
       "      <td>0.040333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953822</th>\n",
       "      <td>11.385239</td>\n",
       "      <td>5.389606</td>\n",
       "      <td>5.222381</td>\n",
       "      <td>7.172846</td>\n",
       "      <td>8.650382</td>\n",
       "      <td>0.040024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953823</th>\n",
       "      <td>11.454549</td>\n",
       "      <td>5.389606</td>\n",
       "      <td>5.194398</td>\n",
       "      <td>7.033597</td>\n",
       "      <td>8.487757</td>\n",
       "      <td>0.035293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953824</th>\n",
       "      <td>11.523858</td>\n",
       "      <td>5.376124</td>\n",
       "      <td>5.082464</td>\n",
       "      <td>6.959331</td>\n",
       "      <td>8.379341</td>\n",
       "      <td>0.033167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953825</th>\n",
       "      <td>11.477652</td>\n",
       "      <td>5.271635</td>\n",
       "      <td>4.904071</td>\n",
       "      <td>6.909821</td>\n",
       "      <td>8.283434</td>\n",
       "      <td>0.034021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953826</th>\n",
       "      <td>11.431446</td>\n",
       "      <td>5.170517</td>\n",
       "      <td>4.806129</td>\n",
       "      <td>6.881971</td>\n",
       "      <td>8.277179</td>\n",
       "      <td>0.030305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953827</th>\n",
       "      <td>11.431446</td>\n",
       "      <td>5.109846</td>\n",
       "      <td>4.827117</td>\n",
       "      <td>6.881971</td>\n",
       "      <td>8.258415</td>\n",
       "      <td>0.025842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953828</th>\n",
       "      <td>11.431446</td>\n",
       "      <td>5.039063</td>\n",
       "      <td>4.834113</td>\n",
       "      <td>6.866499</td>\n",
       "      <td>8.235480</td>\n",
       "      <td>0.028017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953829</th>\n",
       "      <td>11.431446</td>\n",
       "      <td>4.948056</td>\n",
       "      <td>4.771150</td>\n",
       "      <td>6.816988</td>\n",
       "      <td>8.235480</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953830</th>\n",
       "      <td>11.431446</td>\n",
       "      <td>4.904238</td>\n",
       "      <td>4.711686</td>\n",
       "      <td>6.736534</td>\n",
       "      <td>8.252160</td>\n",
       "      <td>0.033653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953831</th>\n",
       "      <td>11.431446</td>\n",
       "      <td>4.860421</td>\n",
       "      <td>4.673209</td>\n",
       "      <td>6.683929</td>\n",
       "      <td>8.252160</td>\n",
       "      <td>0.034021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953832</th>\n",
       "      <td>11.454549</td>\n",
       "      <td>4.860421</td>\n",
       "      <td>4.648723</td>\n",
       "      <td>6.652985</td>\n",
       "      <td>8.277179</td>\n",
       "      <td>0.038280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953833</th>\n",
       "      <td>11.454549</td>\n",
       "      <td>4.685149</td>\n",
       "      <td>4.648723</td>\n",
       "      <td>6.649890</td>\n",
       "      <td>8.289689</td>\n",
       "      <td>0.039934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953834</th>\n",
       "      <td>11.454549</td>\n",
       "      <td>4.449206</td>\n",
       "      <td>4.648723</td>\n",
       "      <td>6.649890</td>\n",
       "      <td>8.306368</td>\n",
       "      <td>0.040024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953835</th>\n",
       "      <td>11.477652</td>\n",
       "      <td>4.375053</td>\n",
       "      <td>4.645226</td>\n",
       "      <td>6.646796</td>\n",
       "      <td>8.356406</td>\n",
       "      <td>0.041221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953836</th>\n",
       "      <td>11.454549</td>\n",
       "      <td>4.300899</td>\n",
       "      <td>4.603251</td>\n",
       "      <td>6.646796</td>\n",
       "      <td>8.421039</td>\n",
       "      <td>0.038201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953837</th>\n",
       "      <td>11.500755</td>\n",
       "      <td>4.243599</td>\n",
       "      <td>4.596255</td>\n",
       "      <td>6.634418</td>\n",
       "      <td>8.464823</td>\n",
       "      <td>0.045027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953838</th>\n",
       "      <td>11.523858</td>\n",
       "      <td>4.226746</td>\n",
       "      <td>4.610246</td>\n",
       "      <td>6.625135</td>\n",
       "      <td>8.471078</td>\n",
       "      <td>0.051434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953839</th>\n",
       "      <td>11.546961</td>\n",
       "      <td>4.243599</td>\n",
       "      <td>4.606749</td>\n",
       "      <td>6.640607</td>\n",
       "      <td>8.481502</td>\n",
       "      <td>0.037023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953840</th>\n",
       "      <td>11.546961</td>\n",
       "      <td>4.243599</td>\n",
       "      <td>4.529795</td>\n",
       "      <td>6.671551</td>\n",
       "      <td>8.548220</td>\n",
       "      <td>0.051031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953841</th>\n",
       "      <td>11.523858</td>\n",
       "      <td>4.226746</td>\n",
       "      <td>4.445845</td>\n",
       "      <td>6.690118</td>\n",
       "      <td>8.669146</td>\n",
       "      <td>0.068672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953842</th>\n",
       "      <td>11.477652</td>\n",
       "      <td>4.226746</td>\n",
       "      <td>4.452840</td>\n",
       "      <td>6.693212</td>\n",
       "      <td>8.729609</td>\n",
       "      <td>0.026598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953843</th>\n",
       "      <td>11.477652</td>\n",
       "      <td>4.243599</td>\n",
       "      <td>4.477326</td>\n",
       "      <td>6.603474</td>\n",
       "      <td>8.700420</td>\n",
       "      <td>0.051031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953844</th>\n",
       "      <td>11.477652</td>\n",
       "      <td>4.257081</td>\n",
       "      <td>4.487820</td>\n",
       "      <td>6.504453</td>\n",
       "      <td>8.596173</td>\n",
       "      <td>0.109318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953845</th>\n",
       "      <td>11.477652</td>\n",
       "      <td>4.270564</td>\n",
       "      <td>4.484322</td>\n",
       "      <td>6.476603</td>\n",
       "      <td>8.464823</td>\n",
       "      <td>-0.083944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3953846 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ED       ECU       FCU        FD       APL     Force\n",
       "0         3.438920  1.699614  5.369880  1.410052  5.872086  0.417777\n",
       "1         3.444880  1.705788  5.466240  1.410052  5.979987  0.411065\n",
       "2         3.450840  1.724604  5.553840  1.410052  6.076530  0.414705\n",
       "3         3.462760  1.736952  5.575740  1.410052  6.121962  0.414568\n",
       "4         3.489580  1.755768  5.615160  1.419298  6.303690  0.413104\n",
       "5         3.519380  1.768116  5.689620  1.447671  6.621714  0.414177\n",
       "6         3.537260  1.774290  5.724660  1.456916  6.848874  0.414065\n",
       "7         3.564080  1.793106  5.750940  1.456916  6.928380  0.413938\n",
       "8         3.620700  1.799280  5.821020  1.484970  6.979491  0.413693\n",
       "9         3.719040  1.818096  5.921760  1.503780  7.104429  0.413783\n",
       "10        3.799500  1.818096  6.009360  1.522589  7.189614  0.414913\n",
       "11        3.850160  1.818096  6.079440  1.569771  7.189614  0.412784\n",
       "12        3.909760  1.830444  6.153900  1.645008  7.240725  0.413404\n",
       "13        3.966380  1.842792  6.250260  1.682626  7.286157  0.417892\n",
       "14        4.017040  1.867782  6.377280  1.682626  7.314552  0.406873\n",
       "15        4.079620  1.905120  6.552480  1.691872  7.325910  0.385446\n",
       "16        4.133260  1.948632  6.710160  1.720245  7.331589  0.380451\n",
       "17        4.139220  2.004786  6.815280  1.748299  7.399737  0.385654\n",
       "18        4.154120  2.060646  6.902880  1.767108  7.530354  0.384344\n",
       "19        4.228620  2.091810  7.003620  1.795163  7.643934  0.382899\n",
       "20        4.297160  2.116800  7.130640  1.823536  7.729119  0.384362\n",
       "21        4.326960  2.154138  7.292700  1.842345  7.808625  0.384245\n",
       "22        4.356760  2.172954  7.450380  1.964446  7.854057  0.383811\n",
       "23        4.446160  2.185302  7.586160  2.152538  7.905168  0.383533\n",
       "24        4.550460  2.203824  7.735080  2.293447  8.047143  0.384271\n",
       "25        4.586220  2.216466  7.892760  2.368684  8.143686  0.384630\n",
       "26        4.607080  2.228814  8.050440  2.406302  8.268624  0.382328\n",
       "27        4.669660  2.234988  8.194980  2.434357  8.478747  0.384667\n",
       "28        4.768000  2.241456  8.300100  2.434357  8.586648  0.386576\n",
       "29        4.854420  2.241456  8.322000  2.443921  8.677512  0.374676\n",
       "...            ...       ...       ...       ...       ...       ...\n",
       "3953816  10.974003  5.345788  5.348306  7.268773  8.838026  0.040024\n",
       "3953817  11.066416  5.345788  5.285343  7.305905  8.748374  0.039451\n",
       "3953818  11.089519  5.345788  5.253862  7.336850  8.662891  0.039885\n",
       "3953819  11.158828  5.345788  5.236372  7.361605  8.646212  0.040024\n",
       "3953820  11.315930  5.376124  5.232875  7.364699  8.662891  0.039176\n",
       "3953821  11.385239  5.376124  5.229377  7.312094  8.717100  0.040333\n",
       "3953822  11.385239  5.389606  5.222381  7.172846  8.650382  0.040024\n",
       "3953823  11.454549  5.389606  5.194398  7.033597  8.487757  0.035293\n",
       "3953824  11.523858  5.376124  5.082464  6.959331  8.379341  0.033167\n",
       "3953825  11.477652  5.271635  4.904071  6.909821  8.283434  0.034021\n",
       "3953826  11.431446  5.170517  4.806129  6.881971  8.277179  0.030305\n",
       "3953827  11.431446  5.109846  4.827117  6.881971  8.258415  0.025842\n",
       "3953828  11.431446  5.039063  4.834113  6.866499  8.235480  0.028017\n",
       "3953829  11.431446  4.948056  4.771150  6.816988  8.235480  0.032508\n",
       "3953830  11.431446  4.904238  4.711686  6.736534  8.252160  0.033653\n",
       "3953831  11.431446  4.860421  4.673209  6.683929  8.252160  0.034021\n",
       "3953832  11.454549  4.860421  4.648723  6.652985  8.277179  0.038280\n",
       "3953833  11.454549  4.685149  4.648723  6.649890  8.289689  0.039934\n",
       "3953834  11.454549  4.449206  4.648723  6.649890  8.306368  0.040024\n",
       "3953835  11.477652  4.375053  4.645226  6.646796  8.356406  0.041221\n",
       "3953836  11.454549  4.300899  4.603251  6.646796  8.421039  0.038201\n",
       "3953837  11.500755  4.243599  4.596255  6.634418  8.464823  0.045027\n",
       "3953838  11.523858  4.226746  4.610246  6.625135  8.471078  0.051434\n",
       "3953839  11.546961  4.243599  4.606749  6.640607  8.481502  0.037023\n",
       "3953840  11.546961  4.243599  4.529795  6.671551  8.548220  0.051031\n",
       "3953841  11.523858  4.226746  4.445845  6.690118  8.669146  0.068672\n",
       "3953842  11.477652  4.226746  4.452840  6.693212  8.729609  0.026598\n",
       "3953843  11.477652  4.243599  4.477326  6.603474  8.700420  0.051031\n",
       "3953844  11.477652  4.257081  4.487820  6.504453  8.596173  0.109318\n",
       "3953845  11.477652  4.270564  4.484322  6.476603  8.464823 -0.083944\n",
       "\n",
       "[3953846 rows x 6 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df.reset_index().drop(columns=['index'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data processing and deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process original dataset, create windows (window_size samples(rows), about 1 second)\n",
    "data = []\n",
    "window = 1\n",
    "while window*window_size < len(result_df):\n",
    "    data_window = result_df[(window - 1)*window_size:window*window_size]\n",
    "    data.append(data_window.values)\n",
    "    window += 1\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3953845"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "seed(101)\n",
    "shuffle(data)\n",
    "#cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract label from each window\n",
    "labels = []\n",
    "for i in data:\n",
    "    label = i[0][5]\n",
    "    labels.append(label)\n",
    "labels = np.array(labels)\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 32.66822478,  60.73990062,   6.44101519,   8.00938985,\n",
       "          19.81348311]],\n",
       "\n",
       "       [[269.        , 218.3       , 313.2       ,  91.5       ,\n",
       "         144.3       ]],\n",
       "\n",
       "       [[746.1       , 214.3       , 151.        ,  71.14      ,\n",
       "         111.6       ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[139.8       , 103.4       , 126.8       ,  44.11      ,\n",
       "          70.19      ]],\n",
       "\n",
       "       [[160.01251386,  79.54641042, 142.74974036,  27.46290168,\n",
       "          59.52480069]],\n",
       "\n",
       "       [[ 60.6556293 ,  56.94253201,   7.95839292,  13.16470267,\n",
       "          38.21171742]]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features from each window\n",
    "features = []\n",
    "for i in data:\n",
    "    new = np.delete(i, 5, 1)\n",
    "    features.append(new)\n",
    "features = np.array(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3953845, 1, 5)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.resize(features[:int(len(data)*0.8)], (int(len(data)*0.8), -1))\n",
    "# Y_train = labels[:int(len(data)*0.8)]\n",
    "# X_test = np.resize(features[int(len(data)*0.8):], ((features.shape[0] - int(len(data)*0.8)), -1))\n",
    "# Y_test = labels[int(len(data)*0.8):]\n",
    "\n",
    "# # clf = svm.SVC()\n",
    "# clf = sklearn.linear_model.LogisticRegression()\n",
    "# clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# Y_predict = clf.predict(X_test)\n",
    "# metrics.accuracy_score(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[32.6682247815, 60.73990061625, 6.44101518813...</td>\n",
       "      <td>2.150035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[269.0, 218.3, 313.2, 91.5, 144.3]]</td>\n",
       "      <td>28.517166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[746.1, 214.3, 151.0, 71.14, 111.6]]</td>\n",
       "      <td>17.624485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[171.702714848, 22.195470873435003, 17.975763...</td>\n",
       "      <td>5.718914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[35.34994472625, 42.760890033840006, 31.24012...</td>\n",
       "      <td>8.093588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[18.19, 16.18, 10.27, 22.35, 26.07]]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[1062.0, 320.3, 88.19, 66.34, 96.71]]</td>\n",
       "      <td>22.768789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[133.2, 107.8, 63.71, 27.38, 42.33]]</td>\n",
       "      <td>6.795353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[41.9882, 15.3174, 21.12036, 38.67044, 49.816...</td>\n",
       "      <td>3.809519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[769.4, 358.6, 112.3, 94.33, 77.5]]</td>\n",
       "      <td>25.484527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[58.3477248585, 77.60309672808, 27.3320981578...</td>\n",
       "      <td>10.289505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[64.1296, 91.6104, 75.774, 86.26728, 98.70102]]</td>\n",
       "      <td>4.929033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[117.94691902455, 146.18969265357, 95.8432709...</td>\n",
       "      <td>17.527671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[233.71160702400002, 266.41306269344, 32.9922...</td>\n",
       "      <td>2.960635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[18.41, 25.73, 7.7379999999999995, 18.08, 33....</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[318.5, 214.4, 267.2, 93.33, 171.6]]</td>\n",
       "      <td>24.810383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[95.1514, 67.7082, 48.4428, 55.85376, 163.5552]]</td>\n",
       "      <td>11.899720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[622.86130144, 335.24093137006, 38.9667264791...</td>\n",
       "      <td>4.981107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[4.841723463885, 5.382904970168999, 12.312712...</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[45.79, 116.3, 26.99, 18.8, 61.4]]</td>\n",
       "      <td>2.744315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[22.89, 16.43, 17.64, 21.32, 35.82]]</td>\n",
       "      <td>3.226007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[185.6, 51.35, 55.97, 16.95, 48.04]]</td>\n",
       "      <td>2.916844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[[67.13, 27.37, 19.74, 24.57, 76.22]]</td>\n",
       "      <td>2.796757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[8.748908159145, 45.424447157159996, 2.617416...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[[229.922688128, 46.514426431800004, 16.947377...</td>\n",
       "      <td>7.476467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[129.1, 142.0, 59.16, 64.44, 66.36]]</td>\n",
       "      <td>5.380970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[21.63182, 11.27196, 17.81784, 8.317492, 33.7...</td>\n",
       "      <td>2.080142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[651.97128808, 235.6056817089, 146.4575258240...</td>\n",
       "      <td>5.504967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[[18.87, 43.29, 12.36, 12.6, 30.31]]</td>\n",
       "      <td>1.434456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[[36.3858, 46.1286, 40.69458, 86.2354, 69.1134...</td>\n",
       "      <td>2.591677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953815</th>\n",
       "      <td>[[60.11928530685, 80.60859699561, 59.971399841...</td>\n",
       "      <td>13.917073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953816</th>\n",
       "      <td>[[7.7672837368, 4.284046086581, 4.501811218905...</td>\n",
       "      <td>0.048660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953817</th>\n",
       "      <td>[[53.37, 28.1, 28.6, 17.12, 55.28]]</td>\n",
       "      <td>3.440801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953818</th>\n",
       "      <td>[[42.763000000000005, 108.633, 13.60428, 83.36...</td>\n",
       "      <td>4.644213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953819</th>\n",
       "      <td>[[32.0052, 21.79716, 27.156, 23.473244, 60.140...</td>\n",
       "      <td>2.621343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953820</th>\n",
       "      <td>[[176.6, 161.1, 148.7, 54.68, 86.73]]</td>\n",
       "      <td>15.047428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953821</th>\n",
       "      <td>[[69.19, 169.2, 151.3, 45.78, 74.19]]</td>\n",
       "      <td>12.229476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953822</th>\n",
       "      <td>[[76.735, 28.64442, 27.76482, 46.1622400000000...</td>\n",
       "      <td>7.923360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953823</th>\n",
       "      <td>[[12.48, 5.492999999999999, 3.758, 15.94, 4.511]]</td>\n",
       "      <td>0.010780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953824</th>\n",
       "      <td>[[4.13, 6.837999999999999, 8.612, 9.289, 10.55]]</td>\n",
       "      <td>0.062238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953825</th>\n",
       "      <td>[[253.0, 184.4, 129.9, 75.2, 148.3]]</td>\n",
       "      <td>14.230757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953826</th>\n",
       "      <td>[[257.785103912, 59.42386507193001, 202.773889...</td>\n",
       "      <td>29.936210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953827</th>\n",
       "      <td>[[18.3982241058, 24.187978200960004, 12.790360...</td>\n",
       "      <td>0.816088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953828</th>\n",
       "      <td>[[20.59235860605, 27.60740964306, 4.0117633924...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953829</th>\n",
       "      <td>[[155.9, 197.2, 118.9, 105.5, 91.68]]</td>\n",
       "      <td>5.601916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953830</th>\n",
       "      <td>[[447.092429728, 101.01720001167, 47.991336381...</td>\n",
       "      <td>1.881656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953831</th>\n",
       "      <td>[[19.89, 7.5729999999999995, 8.294, 10.36, 15.2]]</td>\n",
       "      <td>0.466635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953832</th>\n",
       "      <td>[[26.00455704, 61.7297360337, 20.717392672532,...</td>\n",
       "      <td>4.009996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953833</th>\n",
       "      <td>[[8.439, 6.53, 5.5, 13.74, 25.61]]</td>\n",
       "      <td>0.004631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953834</th>\n",
       "      <td>[[74.68183724925001, 84.29798355156, 102.30840...</td>\n",
       "      <td>1.353770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953835</th>\n",
       "      <td>[[27.012233625300002, 16.001139448269, 5.25413...</td>\n",
       "      <td>1.070830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953836</th>\n",
       "      <td>[[42.4352, 21.51786, 19.2282, 51.07176, 70.533...</td>\n",
       "      <td>5.415811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953837</th>\n",
       "      <td>[[8.686, 5.1610000000000005, 8.532, 30.06, 11....</td>\n",
       "      <td>0.015217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953838</th>\n",
       "      <td>[[17.36, 19.12, 21.19, 20.67, 15.96]]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953839</th>\n",
       "      <td>[[571.57227736, 514.0181181775, 236.3538337695...</td>\n",
       "      <td>5.939335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953840</th>\n",
       "      <td>[[149.9487770319, 134.36565866694, 70.87529072...</td>\n",
       "      <td>16.779885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953841</th>\n",
       "      <td>[[557.71037896, 120.87009651046002, 164.331850...</td>\n",
       "      <td>4.319787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953842</th>\n",
       "      <td>[[139.8, 103.4, 126.8, 44.11, 70.19]]</td>\n",
       "      <td>13.913933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953843</th>\n",
       "      <td>[[160.012513864, 79.5464104196, 142.7497403601...</td>\n",
       "      <td>16.530886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953844</th>\n",
       "      <td>[[60.6556292958, 56.94253201476, 7.95839292346...</td>\n",
       "      <td>4.892470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3953845 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  features     labels\n",
       "0        [[32.6682247815, 60.73990061625, 6.44101518813...   2.150035\n",
       "1                     [[269.0, 218.3, 313.2, 91.5, 144.3]]  28.517166\n",
       "2                    [[746.1, 214.3, 151.0, 71.14, 111.6]]  17.624485\n",
       "3        [[171.702714848, 22.195470873435003, 17.975763...   5.718914\n",
       "4        [[35.34994472625, 42.760890033840006, 31.24012...   8.093588\n",
       "5                    [[18.19, 16.18, 10.27, 22.35, 26.07]]   0.000000\n",
       "6                   [[1062.0, 320.3, 88.19, 66.34, 96.71]]  22.768789\n",
       "7                    [[133.2, 107.8, 63.71, 27.38, 42.33]]   6.795353\n",
       "8        [[41.9882, 15.3174, 21.12036, 38.67044, 49.816...   3.809519\n",
       "9                     [[769.4, 358.6, 112.3, 94.33, 77.5]]  25.484527\n",
       "10       [[58.3477248585, 77.60309672808, 27.3320981578...  10.289505\n",
       "11        [[64.1296, 91.6104, 75.774, 86.26728, 98.70102]]   4.929033\n",
       "12       [[117.94691902455, 146.18969265357, 95.8432709...  17.527671\n",
       "13       [[233.71160702400002, 266.41306269344, 32.9922...   2.960635\n",
       "14       [[18.41, 25.73, 7.7379999999999995, 18.08, 33....   0.000000\n",
       "15                   [[318.5, 214.4, 267.2, 93.33, 171.6]]  24.810383\n",
       "16       [[95.1514, 67.7082, 48.4428, 55.85376, 163.5552]]  11.899720\n",
       "17       [[622.86130144, 335.24093137006, 38.9667264791...   4.981107\n",
       "18       [[4.841723463885, 5.382904970168999, 12.312712...   0.034700\n",
       "19                     [[45.79, 116.3, 26.99, 18.8, 61.4]]   2.744315\n",
       "20                   [[22.89, 16.43, 17.64, 21.32, 35.82]]   3.226007\n",
       "21                   [[185.6, 51.35, 55.97, 16.95, 48.04]]   2.916844\n",
       "22                   [[67.13, 27.37, 19.74, 24.57, 76.22]]   2.796757\n",
       "23       [[8.748908159145, 45.424447157159996, 2.617416...   0.000000\n",
       "24       [[229.922688128, 46.514426431800004, 16.947377...   7.476467\n",
       "25                   [[129.1, 142.0, 59.16, 64.44, 66.36]]   5.380970\n",
       "26       [[21.63182, 11.27196, 17.81784, 8.317492, 33.7...   2.080142\n",
       "27       [[651.97128808, 235.6056817089, 146.4575258240...   5.504967\n",
       "28                    [[18.87, 43.29, 12.36, 12.6, 30.31]]   1.434456\n",
       "29       [[36.3858, 46.1286, 40.69458, 86.2354, 69.1134...   2.591677\n",
       "...                                                    ...        ...\n",
       "3953815  [[60.11928530685, 80.60859699561, 59.971399841...  13.917073\n",
       "3953816  [[7.7672837368, 4.284046086581, 4.501811218905...   0.048660\n",
       "3953817                [[53.37, 28.1, 28.6, 17.12, 55.28]]   3.440801\n",
       "3953818  [[42.763000000000005, 108.633, 13.60428, 83.36...   4.644213\n",
       "3953819  [[32.0052, 21.79716, 27.156, 23.473244, 60.140...   2.621343\n",
       "3953820              [[176.6, 161.1, 148.7, 54.68, 86.73]]  15.047428\n",
       "3953821              [[69.19, 169.2, 151.3, 45.78, 74.19]]  12.229476\n",
       "3953822  [[76.735, 28.64442, 27.76482, 46.1622400000000...   7.923360\n",
       "3953823  [[12.48, 5.492999999999999, 3.758, 15.94, 4.511]]   0.010780\n",
       "3953824   [[4.13, 6.837999999999999, 8.612, 9.289, 10.55]]   0.062238\n",
       "3953825               [[253.0, 184.4, 129.9, 75.2, 148.3]]  14.230757\n",
       "3953826  [[257.785103912, 59.42386507193001, 202.773889...  29.936210\n",
       "3953827  [[18.3982241058, 24.187978200960004, 12.790360...   0.816088\n",
       "3953828  [[20.59235860605, 27.60740964306, 4.0117633924...   0.000000\n",
       "3953829              [[155.9, 197.2, 118.9, 105.5, 91.68]]   5.601916\n",
       "3953830  [[447.092429728, 101.01720001167, 47.991336381...   1.881656\n",
       "3953831  [[19.89, 7.5729999999999995, 8.294, 10.36, 15.2]]   0.466635\n",
       "3953832  [[26.00455704, 61.7297360337, 20.717392672532,...   4.009996\n",
       "3953833                 [[8.439, 6.53, 5.5, 13.74, 25.61]]   0.004631\n",
       "3953834  [[74.68183724925001, 84.29798355156, 102.30840...   1.353770\n",
       "3953835  [[27.012233625300002, 16.001139448269, 5.25413...   1.070830\n",
       "3953836  [[42.4352, 21.51786, 19.2282, 51.07176, 70.533...   5.415811\n",
       "3953837  [[8.686, 5.1610000000000005, 8.532, 30.06, 11....   0.015217\n",
       "3953838              [[17.36, 19.12, 21.19, 20.67, 15.96]]   0.000000\n",
       "3953839  [[571.57227736, 514.0181181775, 236.3538337695...   5.939335\n",
       "3953840  [[149.9487770319, 134.36565866694, 70.87529072...  16.779885\n",
       "3953841  [[557.71037896, 120.87009651046002, 164.331850...   4.319787\n",
       "3953842              [[139.8, 103.4, 126.8, 44.11, 70.19]]  13.913933\n",
       "3953843  [[160.012513864, 79.5464104196, 142.7497403601...  16.530886\n",
       "3953844  [[60.6556292958, 56.94253201476, 7.95839292346...   4.892470\n",
       "\n",
       "[3953845 rows x 2 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the features and labels\n",
    "k = list(zip(features, labels))\n",
    "activity_data = pd.DataFrame(k)\n",
    "activity_data.columns = ['features', 'labels']\n",
    "activity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the size of activity. The final output of neural net \n",
    "# # has to have max_index + 1 output\n",
    "# # max_index = activity_data['labels'].max()\n",
    "# # label_size = int(max_index + 1)\n",
    "# label_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU...\")\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to test, validation, and train\n",
    "valid_size = 0.1\n",
    "test_size = 0.1\n",
    "activity_data.columns = [\"features\", \"labels\"]\n",
    "activity_data_train = activity_data[:int(len(activity_data)*(1-valid_size-test_size))]\n",
    "activity_data_valid = activity_data[int(len(activity_data)*(1-valid_size-test_size)):int(len(activity_data)*(1-test_size))]\n",
    "activity_data_test = activity_data[int(len(activity_data)*(1-test_size)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3163076, 2)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our dataset in pytorch\n",
    "class DatasetSpineTrack(Dataset):\n",
    "    \n",
    "    def __init__(self, file, transform=None):\n",
    "        #self.data = pd.read_csv(file_path)\n",
    "        self.data = file\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image as ndarray type (Height * Width * Channels)\n",
    "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
    "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
    "        \n",
    "        features = torch.tensor(self.data[\"features\"].iloc[index])[0]\n",
    "#         labels = torch.tensor(self.data[\"labels\"].iloc[index], dtype=torch.long)\n",
    "        labels = torch.tensor([self.data[\"labels\"].iloc[index]], dtype=torch.double)\n",
    "        #print(labels.type())\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             image = self.transform(image)\n",
    "            \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([269.0000, 218.3000, 313.2000,  91.5000, 144.3000], dtype=torch.float64)\n",
      "tensor([28.5172], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# construct training and testing dataset in csv\n",
    "# train_dataset = DatasetSpineTrack(\"./activity_data_train.csv\")\n",
    "# valid_dataset = DatasetSpineTrack(\"./activity_data_valid.csv\")\n",
    "# test_dataset = DatasetSpineTrack(\"./activity_data_test.csv\")\n",
    "train_dataset = DatasetSpineTrack(activity_data_train)\n",
    "valid_dataset = DatasetSpineTrack(activity_data_valid)\n",
    "test_dataset = DatasetSpineTrack(activity_data_test)\n",
    "feature, label = train_dataset.__getitem__(1)\n",
    "print(feature)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Network Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_on_gpu = False\n",
    "# train_on_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionModel(\n",
      "  (fc1): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(5, 32, bias=True)\n",
    "        self.fc2 = nn.Linear(32, 64, bias=True)\n",
    "        self.fc3 = nn.Linear(64, 1, bias=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "#         print(\"forward shape 1: \", x.shape)\n",
    "\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add 2nd and 3rd hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "model = RegressionModel()\n",
    "model = model.double()\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Run all above \n",
    "<a name='bookmark' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the Network\n",
    "\n",
    "Remember to look at how the training and validation loss decreases over time; if the validation loss ever increases it indicates possible overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 32.135389 \tValidation Loss: 14.879943\n",
      "Validation loss decreased (inf --> 14.879943).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 30.953191 \tValidation Loss: 13.570464\n",
      "Validation loss decreased (14.879943 --> 13.570464).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 30.620115 \tValidation Loss: 14.987109\n",
      "Epoch: 4 \tTraining Loss: 30.549096 \tValidation Loss: 14.781974\n",
      "Epoch: 5 \tTraining Loss: 30.375761 \tValidation Loss: 14.806689\n",
      "Epoch: 6 \tTraining Loss: 30.272931 \tValidation Loss: 14.985062\n",
      "Epoch: 7 \tTraining Loss: 30.205898 \tValidation Loss: 13.127934\n",
      "Validation loss decreased (13.570464 --> 13.127934).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 30.199949 \tValidation Loss: 13.703405\n",
      "Epoch: 9 \tTraining Loss: 30.167287 \tValidation Loss: 15.104831\n",
      "Epoch: 10 \tTraining Loss: 30.159152 \tValidation Loss: 15.257221\n",
      "Epoch: 11 \tTraining Loss: 30.058509 \tValidation Loss: 13.798360\n",
      "Epoch: 12 \tTraining Loss: 30.083905 \tValidation Loss: 13.960421\n",
      "Epoch: 13 \tTraining Loss: 30.101501 \tValidation Loss: 12.166047\n",
      "Validation loss decreased (13.127934 --> 12.166047).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 30.110945 \tValidation Loss: 13.265986\n",
      "Epoch: 15 \tTraining Loss: 30.131986 \tValidation Loss: 14.995994\n",
      "Epoch: 16 \tTraining Loss: 30.010208 \tValidation Loss: 15.574392\n",
      "Epoch: 17 \tTraining Loss: 30.081971 \tValidation Loss: 15.931262\n",
      "Epoch: 18 \tTraining Loss: 30.019474 \tValidation Loss: 13.785980\n",
      "Epoch: 19 \tTraining Loss: 30.041704 \tValidation Loss: 13.713177\n",
      "Epoch: 20 \tTraining Loss: 29.925482 \tValidation Loss: 13.566893\n",
      "Epoch: 21 \tTraining Loss: 29.959361 \tValidation Loss: 14.218252\n",
      "Epoch: 22 \tTraining Loss: 29.917115 \tValidation Loss: 13.719345\n",
      "Epoch: 23 \tTraining Loss: 29.957325 \tValidation Loss: 13.447627\n",
      "Epoch: 24 \tTraining Loss: 29.991514 \tValidation Loss: 13.951810\n",
      "Epoch: 25 \tTraining Loss: 29.970489 \tValidation Loss: 12.889396\n",
      "Epoch: 26 \tTraining Loss: 29.950628 \tValidation Loss: 14.162393\n",
      "Epoch: 27 \tTraining Loss: 29.936935 \tValidation Loss: 12.098011\n",
      "Validation loss decreased (12.166047 --> 12.098011).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 30.006521 \tValidation Loss: 13.695304\n",
      "Epoch: 29 \tTraining Loss: 29.841411 \tValidation Loss: 12.751128\n",
      "Epoch: 30 \tTraining Loss: 29.936765 \tValidation Loss: 13.699296\n",
      "Training time: 260 min 43 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 30\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() \n",
    "    for features, labels in trainloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(features)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, labels)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*features.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for features, labels in validloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(features)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, labels)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*features.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainloader.sampler)\n",
    "    valid_loss = valid_loss/len(validloader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_Force_Prediction.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "# output running time\n",
    "running_time = time.time() - start_time\n",
    "sec = running_time % 60\n",
    "miniute = running_time / 60\n",
    "print(\"Training time: {} min {} sec\".format(int(miniute), int(sec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeCNN(nn.Module):\n",
    "    def __init__(self, channel, label_size):\n",
    "        super(TimeCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channel, 32, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        \n",
    "        # bn1 = BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 64, bias=True)\n",
    "        self.fc2 = nn.Linear(64, label_size, bias=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "#         print(\"forward shape 1: \", x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flatten image input\n",
    "        x = x.view(batch_size, -1)\n",
    "#         print(\"forward shape 2: \", x.shape)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = TimeCNN(channel, label_size)\n",
    "model = model.double()\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load on gpu\n",
    "# model.load_state_dict(torch.load('model_Spinetrack_3.pt'))\n",
    "\n",
    "# load on cpu\n",
    "model.load_state_dict(torch.load('model_Force_Prediction_5_subjects.pt', map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n",
    "\n",
    "Test your trained model on previously unseen data! A \"good\" result will be a result that gets more than 70% accuracy on these test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release all the GPU memory cache that can be freed\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall loss and r square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 12.104699\n",
      "\n",
      "Test r square: 0.760794\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "\n",
    "# track test output\n",
    "test_output = []\n",
    "test_label = []\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.eval()\n",
    "torch.no_grad()\n",
    "# iterate over test data\n",
    "for features, labels in testloader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(features)\n",
    "    \n",
    "    test_output.append(output)\n",
    "    test_label.append(labels)\n",
    "    \n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, labels)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*features.size(0)\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(testloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "score = []\n",
    "\n",
    "# calculate mean p value\n",
    "for i in range(len(test_label)):\n",
    "    y_true = test_label[i].detach().numpy()\n",
    "    y_predict = test_output[i].detach().numpy()\n",
    "    score.append(r2_score(y_true, y_predict))\n",
    "print('Test r square: {:.6f}'.format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy (different calculation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off gradients for validation, saves memory and computations\n",
    "torch.no_grad()\n",
    "accuracy = 0\n",
    "for features, labels in testloader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "    loss = model(features)\n",
    "    test_loss += criterion(loss, labels)\n",
    "\n",
    "#     ps = torch.exp(loss)\n",
    "    top_p, top_class = loss.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out pulling_OneH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
